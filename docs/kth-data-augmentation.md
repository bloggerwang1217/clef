# clef-piano-full MIDI Humanization å¯¦ä½œè¨ˆç•«

## èƒŒæ™¯

clef æ˜¯ä¸€å€‹ audio-to-score (A2S) ç ”ç©¶å°ˆæ¡ˆï¼Œç›®æ¨™æ˜¯ ISMIR 2026 / ICLR 2027ã€‚

**æ ¸å¿ƒå“²å­¸**ï¼šã€Œ**Enlightenment**ã€è€Œéã€ŒNoiseã€â€” é€™æ˜¯åœ¨åŠ å…¥éŸ³æ¨‚çŸ¥è­˜ï¼Œä¸æ˜¯åŠ å…¥éš¨æ©Ÿå™ªéŸ³ã€‚æŠŠé€™ä»¶äº‹ç•¶ä½œã€Œ**æ··éŸ³**ã€ä¾†çœ‹å¾…ï¼ŒæŠŠ DAW æ¬åˆ° Python ä¸Šã€‚

**å°ˆæ¡ˆç¾æ³**ï¼š
- **clef-piano-base**ï¼ˆå·²å®Œæˆï¼‰ï¼šZeng baseline æ¯”è¼ƒç”¨ï¼Œç§»é™¤ `**dynam` spineï¼Œuniform velocity (90)
- **clef-piano-full**ï¼ˆå¾…å¯¦ä½œï¼‰ï¼šä¿ç•™ `**dynam` spine (--preset clef-piano-full parameter in humsyn_preprocessor.py)ï¼Œéœ€è¦ rule-based humanization

**é‡è¦åŸå‰‡1**ï¼šå…©å€‹ pipeline å®Œå…¨åˆ†é›¢ï¼Œä¸æœƒäº’ç›¸å½±éŸ¿ã€‚clef-piano-base çš„è¨­å®šä¸æœƒè¢«ä¿®æ”¹ã€‚
**é‡è¦åŸå‰‡2**ï¼šå¯¦ä½œæ™‚è«‹ç¢ºä¿æŒ‰ç…§ KTH rule book çš„é è¨­æ•¸å€¼ï¼Œè«‹ç¢ºèªå¯¦ä½œå¯¦ä½œæ•¸å€¼èˆ‡ rule book ä¸€è‡´
---

## ä¸‰éšæ®µæ¶æ§‹

### Stage 1: Score â†’ MIDI (éŸ³æ¨‚æ€§ç·¨ç¢¼) â€” æœ¬æ¬¡é‡é»

ç”¨ **Partitura** è§£ææ¨‚è­œï¼Œå¯¦ä½œ **KTH è¦å‰‡ç³»çµ±**ï¼š
- Dynamics æ¨™è¨˜ â†’ Velocity æ˜ å°„
- HIGH LOUD: pitch è¶Šé«˜ velocity è¶Šå¼·
- PHRASE ARCH: æ¨‚å¥ä¸­é–“å¼·ï¼Œå…©ç«¯å¼±
- METRICAL ACCENT: ä¸‹æ‹é‡éŸ³
- Micro-timing jitter (Â±10-15ms)
- Chord asynchrony (melody lead 20-50ms)
- Final ritardando (å¹³æ–¹æ ¹å‡½æ•¸)
- Auto pedal (syncopated pedaling)
- **æ‰€æœ‰åƒæ•¸å¯ randomize** ç”¢ç”Ÿå¤šæ¨£æ€§

### Stage 2: MIDI â†’ Audio (éŸ³è‰²æ¸²æŸ“) â€” ç²¾ç°¡

- æ²¿ç”¨ç¾æœ‰ FluidSynth pipeline
- 4 å€‹ SoundFont (TimGM6mb, FluidR3_GM, UprightPianoKW, SalamanderGrandPiano)
- ä¿æŒè¨Šè™Ÿä¹¾æ·¨

### Stage 3: Audio â†’ Audio (çœŸå¯¦ä¸–ç•Œæ¨¡æ“¬) â€” æš«ç·©

- Piano solo å¯ä»¥å°‘åšï¼ˆASAP å¤ ä¹¾æ·¨ï¼‰
- ç•™çµ¦ clef-tutti èªçœŸåš

---

## æª”æ¡ˆçµæ§‹èˆ‡è·è²¬

```
src/audio/humanize/                # æ–°å¢ç›®éŒ„
â”œâ”€â”€ __init__.py                    # å…¬é–‹ API exports
â”œâ”€â”€ config.py                      # RuleConfig + HumanizationConfig
â”œâ”€â”€ metadata.py                    # HumanizationMetadata for reproducibility
â”œâ”€â”€ analysis/                      # åˆ†æå·¥å…·
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ non_chord_tone.py          # â­ NCT heuristic detection
â”œâ”€â”€ rules/                         # KTH è¦å‰‡å¯¦ä½œ
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ base.py                    # Rule æŠ½è±¡åŸºåº•é¡åˆ¥
â”‚   â”‚
â”‚   â”‚  # === Velocity è¦å‰‡ ===
â”‚   â”œâ”€â”€ high_loud.py               # Pitch â†’ velocity
â”‚   â”œâ”€â”€ phrase_arch.py             # Phrase position â†’ velocity + tempo
â”‚   â”œâ”€â”€ duration_contrast.py       # Duration â†’ velocity + duration
â”‚   â”œâ”€â”€ melodic_charge.py          # â­ éå’Œå¼¦éŸ³/å°éŸ³ â†’ velocity (éœ€å’Œè²åˆ†æ)
â”‚   â”‚
â”‚   â”‚  # === Timing è¦å‰‡ ===
â”‚   â”œâ”€â”€ rubato.py                  # â­ Phrase/beat level tempo variation
â”‚   â”œâ”€â”€ final_ritard.py            # End section slowdown
â”‚   â”œâ”€â”€ timing.py                  # Micro-timing jitter + chord async
â”‚   â”œâ”€â”€ fermata.py                 # â­ Fermata duration + pause
â”‚   â”œâ”€â”€ dynamics_tempo.py          # â­ Crescâ†’accel, Agogic accent
â”‚   â”œâ”€â”€ articulation_tempo.py      # â­ Tenuto/legato â†’ timing
â”‚   â”œâ”€â”€ punctuation.py             # â­ æ¨‚å¥é–“ micropause (æ°£å£)
â”‚   â”œâ”€â”€ leap.py                    # â­ å¤§è·³ timing/duration èª¿æ•´
â”‚   â”œâ”€â”€ repetition.py              # â­ é‡è¤‡éŸ³ micropause
â”‚   â”‚
â”‚   â”‚  # === Articulation è¦å‰‡ ===
â”‚   â”œâ”€â”€ articulation.py            # Staccato/legato duration
â”‚   â”œâ”€â”€ ornaments.py               # â­ Grace notes, trills, mordents
â”‚   â”‚
â”‚   â”‚  # === Special ===
â”‚   â”œâ”€â”€ pedal.py                   # Auto pedaling (CC64)
â”‚   â”œâ”€â”€ tempo.py                   # â­ Tempo marking â†’ BPM
â”‚   â””â”€â”€ safety.py                  # â­ Social-duration-care, Global normalization
â”‚
â”œâ”€â”€ engine.py                      # HumanizationEngine ä¸»é¡åˆ¥
â”œâ”€â”€ convert.py                     # dB â†” velocity è½‰æ›å·¥å…·
â””â”€â”€ presets.py                     # é¢¨æ ¼é è¨­ (romantic, classical)
```

**å…± 26 å€‹è¦å‰‡/å…ƒä»¶**ï¼š
| é¡åˆ¥ | è¦å‰‡æ•¸ | è¦å‰‡åç¨± |
|------|--------|----------|
| Velocity | 4 | HighLoud, PhraseArch(vel), DurationContrast(vel), **MelodicCharge** |
| Timing | 12 | PhraseRubato, BeatRubato, FinalRitard, MicroTiming, ChordAsync, Fermata, CrescendoTempo, AgogicAccent, ArticulationTempo, **Punctuation**, **Leap**, **Repetition** |
| Articulation | 5 | Staccato, Legato, GraceNote, Trill, Mordent |
| Safety | 2 | **SocialDurationCare**, **GlobalNormalizer** |
| Special | 3 | AutoPedal, TempoInterpreter, **CLI** |

### Gemini / Claude å›é¥‹ç¢ºèª

| å»ºè­° | ç‹€æ…‹ | å°æ‡‰è¦å‰‡ |
|------|------|----------|
| Melodic Charge (æ—‹å¾‹å¼µåŠ›) | âœ… å·²åŠ å…¥ | `melodic_charge.py` |
| Punctuation (æ°£å£) | âœ… å·²åŠ å…¥ | `punctuation.py` |
| Sound Level Envelope (é˜²çˆ†) | âœ… å·²åŠ å…¥ | `safety.py` (GlobalNormalizer) |
| Social-duration-care | âœ… å·²åŠ å…¥ | `safety.py` |
| Leap handling | âœ… å·²åŠ å…¥ | `leap.py` |
| Repetition handling | âœ… å·²åŠ å…¥ | `repetition.py` |
| InÃ©gales | âšª å»¶å¾Œ | å¤å…¸é‹¼ç´ä¸éœ€è¦ |
| Intonation rules | âšª å»¶å¾Œ | ç•™çµ¦ clef-solo/tutti |

### Velocity-Tempo-Duration è€¦åˆé—œä¿‚åœ–

```
Score Feature          Velocity Effect       Tempo Effect         Duration Effect
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
crescendo        â†’     â†‘ velocity       +    â†‘ tempo (accel)      â€”
diminuendo       â†’     â†“ velocity       +    â†“ tempo (rit)        â€”
sf / accent      â†’     â†‘â†‘ velocity      +    agogic delay         â€”
phrase peak      â†’     â†‘ velocity       +    â†‘ tempo              â€”
phrase end       â†’     â†“ velocity       +    â†“ tempo         +    â†“ duration (æ°£å£)
non-chord tone   â†’     â†‘ velocity       +    â€”                +    â†‘ duration
leading tone     â†’     â†‘ velocity       +    â€”                    â€”
tenuto           â†’     â€”                +    slight delay    +    â†‘ duration
staccato         â†’     â€”                +    â€”               +    â†“â†“ duration
large leap up    â†’     â€”                +    micropause      +    â†“ duration (é¦–éŸ³)
large leap down  â†’     â€”                +    micropause      +    â†‘ duration (é¦–éŸ³)
repeated note    â†’     â€”                +    micropause      +    â†“ duration
```

---

## å„æª”æ¡ˆè©³ç´°è¦æ ¼

### `src/audio/humanize/__init__.py`

```python
"""
KTH-style MIDI humanization with k-value system.

Usage:
    from src.audio.humanize import HumanizationEngine, HumanizationConfig

    config = HumanizationConfig().randomize(seed=42)
    engine = HumanizationEngine(config)
    engine.humanize('score.krn', 'output.mid')
"""
from .config import RuleConfig, HumanizationConfig
from .engine import HumanizationEngine
from .presets import ROMANTIC, CLASSICAL, BALANCED

__all__ = [
    'RuleConfig',
    'HumanizationConfig',
    'HumanizationEngine',
    'ROMANTIC', 'CLASSICAL', 'BALANCED',
]
```

---

### `src/audio/humanize/config.py`

**è·è²¬**ï¼šå®šç¾© k å€¼ç³»çµ±çš„è¨­å®šçµæ§‹

**åŒ…å«**ï¼š
- `RuleConfig` dataclass â€” å–®ä¸€è¦å‰‡çš„ k å€¼èˆ‡ç¯„åœ
- `HumanizationConfig` dataclass â€” å®Œæ•´è¨­å®šï¼ŒåŒ…å«æ‰€æœ‰è¦å‰‡
- `randomize()` æ–¹æ³• â€” ç”¢ç”Ÿéš¨æ©ŸåŒ–è¨­å®šå‰¯æœ¬
- `to_dict()` æ–¹æ³• â€” åŒ¯å‡ºè¨­å®šä¾› logging

**ä¾è³´**ï¼š`numpy`ï¼ˆRNGï¼‰

---

### `src/audio/humanize/convert.py`

**è·è²¬**ï¼šdB â†” MIDI velocity è½‰æ›

**åŒ…å«**ï¼š
```python
def velocity_to_dB(velocity: int, reference: int = 64) -> float:
    """Convert MIDI velocity to dB (0 dB = reference velocity)."""

def dB_to_velocity(dB: float, reference: int = 64) -> int:
    """Convert dB back to MIDI velocity, clamped to 1-127."""

def dynamics_to_velocity(marking: str, dynamics_map: dict) -> int:
    """Convert dynamic marking (p, f, etc.) to velocity."""
```

**ä¾è³´**ï¼š`numpy`

**åƒè€ƒ**ï¼šKTH PDF çš„ dB-velocity æ›²ç·š

---

### `src/audio/humanize/rules/base.py`

**è·è²¬**ï¼šè¦å‰‡æŠ½è±¡åŸºåº•é¡åˆ¥

**åŒ…å«**ï¼š
```python
from abc import ABC, abstractmethod

class Rule(ABC):
    """Base class for KTH-style humanization rules."""

    def __init__(self, config: RuleConfig):
        self.config = config

    @property
    def k(self) -> float:
        return self.config.k

    @property
    def enabled(self) -> bool:
        return self.config.enabled

    @abstractmethod
    def apply_velocity(self, note, features: dict) -> float:
        """Return velocity delta in dB."""
        pass

    @abstractmethod
    def apply_timing(self, note, features: dict) -> float:
        """Return timing delta in seconds."""
        pass

    @abstractmethod
    def apply_duration(self, note, features: dict) -> float:
        """Return duration multiplier."""
        pass
```

---

### `src/audio/humanize/rules/high_loud.py`

**è·è²¬**ï¼šå¯¦ä½œ High-loud è¦å‰‡ï¼ˆpitch è¶Šé«˜è¶Šå¤§è²ï¼‰

**å…¬å¼**ï¼š`dB_delta = k Ã— 0.5 Ã— (pitch - 60)`

**åŒ…å«**ï¼š
```python
class HighLoudRule(Rule):
    """High-loud: higher pitches are played louder."""

    SEMITONE_COEFFICIENT = 0.5  # dB per semitone

    def apply_velocity(self, note, features: dict) -> float:
        if not self.enabled:
            return 0.0
        semitones_above_c4 = note.pitch - 60
        return self.k * self.SEMITONE_COEFFICIENT * semitones_above_c4

    def apply_timing(self, note, features: dict) -> float:
        return 0.0  # No timing effect

    def apply_duration(self, note, features: dict) -> float:
        return 1.0  # No duration effect
```

---

### `src/audio/humanize/rules/phrase_arch.py`

**è·è²¬**ï¼šå¯¦ä½œ Phrase-arch è¦å‰‡ï¼ˆæ¨‚å¥å¼§ç·šï¼‰

**å…¬å¼**ï¼š`dB_delta = k Ã— 6 Ã— arch_function(position)`

**åŒ…å«**ï¼š
```python
class PhraseArchRule(Rule):
    """Phrase-arch: louder in middle of phrase, softer at boundaries."""

    MAX_EFFECT_DB = 6.0

    def __init__(self, config: RuleConfig, peak_position: float = 0.6):
        super().__init__(config)
        self.peak_position = peak_position

    def apply_velocity(self, note, features: dict) -> float:
        if not self.enabled:
            return 0.0
        phrase_pos = features.get('phrase_position')  # 0-1
        if phrase_pos is None:
            return 0.0
        # Parabolic arch centered at peak_position
        arch = 1 - ((phrase_pos - self.peak_position) / self.peak_position) ** 2
        return self.k * self.MAX_EFFECT_DB * arch
```

**ä¾è³´**ï¼šéœ€è¦ partitura çš„ `slur_basis` ä¾†åµæ¸¬æ¨‚å¥é‚Šç•Œ

---

### `src/audio/humanize/rules/duration_contrast.py`

**è·è²¬**ï¼šå¯¦ä½œ Duration-contrast è¦å‰‡ï¼ˆé•·éŸ³æ›´é•·æ›´å¤§è²ï¼‰

**åŒ…å«**ï¼š
```python
class DurationContrastRule(Rule):
    """Duration-contrast: longer notes louder and stretched."""

    def apply_velocity(self, note, features: dict) -> float:
        # Relative duration vs local average
        rel_dur = features.get('relative_duration', 1.0)
        return self.k * 3.0 * np.log2(rel_dur)

    def apply_duration(self, note, features: dict) -> float:
        rel_dur = features.get('relative_duration', 1.0)
        return 1.0 + self.k * 0.1 * (rel_dur - 1.0)
```

---

### `src/audio/humanize/rules/melodic_charge.py` â­ æ–°å¢ (Gemini å»ºè­°)

**è·è²¬**ï¼šå¯¦ä½œ Melodic-charge è¦å‰‡ï¼ˆéå’Œå¼¦éŸ³å¼·èª¿ï¼‰

**KTH å®šç¾©**ï¼š*Emphasis on notes remote from current chord/key.*

**å¯¦ä½œæ–¹å¼**ï¼šä½¿ç”¨ **Heuristic-based NCT detection**ï¼ˆä¸éœ€è¦å®Œæ•´å’Œè²åˆ†æï¼‰

**ç‚ºä»€éº¼é‡è¦**ï¼š
- ä¸åªæ˜¯ã€Œé«˜éŸ³å¤§è²ã€(High-loud)
- è€Œæ˜¯ã€Œ**ä¸å’Œè«§**æˆ–**å…·å°å‘æ€§**ã€çš„éŸ³å¤§è²
- é€™æ˜¯è®“æ¼”å¥æœ‰ã€ŒéŸ³æ¨‚æ€§ã€è€Œéã€Œæ©Ÿæ¢°æ€§ã€çš„é—œéµ

**åŒ…å«**ï¼š
```python
class MelodicChargeRule(Rule):
    """
    Melodic-charge: emphasis on non-chord tones.

    Uses heuristic detection based on:
    1. Metric position (weak beat = likely NCT)
    2. Duration (short = likely NCT)
    3. Melodic motion (step-step patterns)
    4. Dissonance with concurrent notes
    """

    def __init__(self, config: RuleConfig, nct_boost_dB: float = 2.0):
        super().__init__(config)
        self.nct_boost_dB = nct_boost_dB
        self.detector = NonChordToneDetector()

    def apply_velocity(self, note, features: dict) -> float:
        if not self.enabled:
            return 0.0

        analysis = self.detector.analyze_note(
            note_idx=features['note_idx'],
            note_array=features['note_array'],
            features=features
        )
        # NCT confidence (0-1) â†’ dB boost
        return self.k * analysis.melodic_charge

    def apply_timing(self, note, features: dict) -> float:
        """Appoggiaturas get agogic accent (slight delay)."""
        if not self.enabled:
            return 0.0

        analysis = self.detector.analyze_note(...)
        if analysis.nct_type == NCTType.APPOGGIATURA:
            return self.k * 0.02  # 20ms delay
        return 0.0
```

**HumanizationConfig è¨­å®š**ï¼š
```python
melodic_charge: RuleConfig = field(default_factory=lambda: RuleConfig(
    k=0.8, k_range=(0.3, 1.2)  # Conservative: heuristic-based
))
nct_boost_dB: float = 2.0
```

---

### `src/audio/humanize/analysis/non_chord_tone.py` â­ æ–°å¢

**è·è²¬**ï¼šHeuristic-based éå’Œå¼¦éŸ³åµæ¸¬ï¼ˆä¸éœ€è¦å’Œè²åˆ†æï¼‰

**æ ¸å¿ƒåŸç†**ï¼šéå’Œå¼¦éŸ³åˆ†é¡åŸºæ–¼**æ¥è¿‘**å’Œ**é›¢é–‹**æ–¹å¼ï¼š

| é¡å‹ | æ¥è¿‘ | é›¢é–‹ | ä½ç½® |
|------|------|------|------|
| Passing Tone | Step | Step (åŒå‘) | å¼±æ‹ |
| Neighbor Tone | Step | Step (åå‘å›åŸ) | å¼±æ‹ |
| Appoggiatura | Leap | Step (åå‘) | **å¼·æ‹** |
| Escape Tone | Step | Leap (åå‘) | å¼±æ‹ |

**åŒ…å«**ï¼š
```python
from dataclasses import dataclass
from enum import Enum

class NCTType(Enum):
    CHORD_TONE = "chord_tone"
    PASSING_TONE = "passing_tone"
    NEIGHBOR_TONE = "neighbor_tone"
    APPOGGIATURA = "appoggiatura"
    ESCAPE_TONE = "escape_tone"
    UNKNOWN = "unknown"

@dataclass
class NCTAnalysis:
    nct_type: NCTType
    confidence: float  # 0.0 - 1.0
    melodic_charge: float  # dB boost


class NonChordToneDetector:
    """
    Heuristic-based NCT detection.
    ~75% accuracy, fast for batch processing.
    """

    def analyze_note(self, note_idx, note_array, features) -> NCTAnalysis:
        score = 0.0
        detected_type = NCTType.UNKNOWN

        note = note_array[note_idx]
        prev = note_array[note_idx - 1] if note_idx > 0 else None
        next = note_array[note_idx + 1] if note_idx < len(note_array) - 1 else None

        # Heuristic 1: ç¯€æ‹ä½ç½®
        if features.get('beat_strength', 0.5) < 0.3:
            score += 0.2

        # Heuristic 2: æ™‚å€¼
        if features.get('duration_ratio', 1.0) < 0.5:
            score += 0.15

        # Heuristic 3: æ—‹å¾‹é‹å‹•
        if prev is not None and next is not None:
            motion = self._analyze_motion(prev, note, next)
            detected_type = motion['type']
            score += motion['score']

        # Heuristic 4: ä¸å”å’ŒéŸ³ç¨‹
        concurrent = self._get_concurrent_pitches(note, note_array)
        score += self._compute_dissonance(note, concurrent)

        confidence = min(score, 1.0)
        melodic_charge = confidence * 2.0  # 0-2 dB

        if detected_type == NCTType.UNKNOWN:
            detected_type = NCTType.PASSING_TONE if score > 0.5 else NCTType.CHORD_TONE

        return NCTAnalysis(detected_type, confidence, melodic_charge)

    def _analyze_motion(self, prev, curr, next) -> dict:
        interval_in = curr['pitch'] - prev['pitch']
        interval_out = next['pitch'] - curr['pitch']
        is_step_in, is_step_out = abs(interval_in) <= 2, abs(interval_out) <= 2
        same_dir = interval_in * interval_out > 0
        opp_dir = interval_in * interval_out < 0

        if is_step_in and is_step_out and same_dir:
            return {'type': NCTType.PASSING_TONE, 'score': 0.4}
        if is_step_in and is_step_out and opp_dir:
            return {'type': NCTType.NEIGHBOR_TONE, 'score': 0.4}
        if not is_step_in and is_step_out and opp_dir:
            return {'type': NCTType.APPOGGIATURA, 'score': 0.35}
        if is_step_in and not is_step_out and opp_dir:
            return {'type': NCTType.ESCAPE_TONE, 'score': 0.3}
        return {'type': NCTType.UNKNOWN, 'score': 0.0}

    def _compute_dissonance(self, note, concurrent_pitches):
        note_pc = note['pitch'] % 12
        dissonant = {1, 2, 6, 10, 11}  # m2, M2, tritone, m7, M7
        score = sum(0.1 for pc in concurrent_pitches
                    if pc != note_pc and min(abs(note_pc - pc), 12 - abs(note_pc - pc)) in dissonant)
        return min(score, 0.25)
```

**æº–ç¢ºåº¦æ¯”è¼ƒ**ï¼š

| æ–¹æ³• | æº–ç¢ºåº¦ | é€Ÿåº¦ | æ¨è–¦ |
|------|--------|------|------|
| ç´”ç¯€æ‹+æ™‚å€¼ | ~60% | âš¡ | Baseline |
| **æ—‹å¾‹é‹å‹•åˆ†æ** | **~75%** | âš¡ | **æ¨è–¦** |
| + Vertical slice | ~80% | ä¸­ | æœ€ä½³ |
| music21 chordify | ~85% | ğŸŒ | å‚™é¸ |

---

### `src/audio/humanize/rules/punctuation.py` â­ æ–°å¢ (Gemini å»ºè­°)

**è·è²¬**ï¼šå¯¦ä½œ Punctuation è¦å‰‡ï¼ˆæ¨‚å¥é–“çš„ã€Œæ°£å£ã€ï¼‰

**KTH å®šç¾©**ï¼š*Automatically locates small tone groups and marks them with lengthening of last note and a following micropause.*

**èˆ‡ PhraseRubato çš„å·®ç•°**ï¼š
- PhraseRubato = tempo è®Šæ…¢ä½†**é€£çºŒ**
- Punctuation = çœŸæ­£çš„**æ–·é–‹ (Silence)**

**ç‚ºä»€éº¼é‡è¦**ï¼šå° A2S æ¨¡å‹ä¾†èªªï¼Œ**Silence æ˜¯åˆ¤æ–·æ¨‚å¥é‚Šç•Œæœ€å¼·çš„ Feature**

**åŒ…å«**ï¼š
```python
class PunctuationRule(Rule):
    """
    Punctuation: create silence (breathing) between phrases.

    Creates actual gaps, not just tempo changes.
    Critical for A2S models to learn phrase boundaries.
    """

    def __init__(self, config: RuleConfig,
                 micropause_ms: float = 30.0,
                 last_note_shorten_ratio: float = 0.15):
        super().__init__(config)
        self.micropause_ms = micropause_ms
        self.last_note_shorten_ratio = last_note_shorten_ratio

    def apply_duration(self, note, features: dict) -> float:
        """Shorten the last note of a phrase to create gap."""
        if not self.enabled:
            return 1.0

        if features.get('is_phrase_end', False):
            # Shorten note to create micropause
            return 1.0 - self.k * self.last_note_shorten_ratio

        return 1.0

    def apply_timing(self, note, features: dict) -> float:
        """Delay the first note of a new phrase."""
        if not self.enabled:
            return 0.0

        if features.get('is_phrase_start', False) and features.get('phrase_number', 0) > 0:
            # Add micropause before new phrase
            return self.k * self.micropause_ms / 1000

        return 0.0
```

**HumanizationConfig è¨­å®š**ï¼š
```python
punctuation: RuleConfig = field(default_factory=lambda: RuleConfig(
    k=1.0, k_range=(0.5, 1.5)
))
micropause_ms: float = 30.0
phrase_end_shorten_ratio: float = 0.15
```

---

### `src/audio/humanize/rules/leap.py` â­ æ–°å¢ (KTH)

**è·è²¬**ï¼šå¯¦ä½œå¤§è·³ç›¸é—œè¦å‰‡

**KTH è¦å‰‡**ï¼š
- **Leap-tone-duration**: ä¸Šè·³ç¸®çŸ­é¦–éŸ³ï¼Œä¸‹è·³å»¶é•·é¦–éŸ³
- **Leap-articulation-dro**: å¤§è·³å¾ŒåŠ  micropause

**åŒ…å«**ï¼š
```python
class LeapRule(Rule):
    """
    Leap handling: adjust timing/duration around large intervals.

    - Upward leap: shorten first note (lighter)
    - Downward leap: lengthen first note (weightier)
    - After large leap: small micropause
    """

    def __init__(self, config: RuleConfig,
                 leap_threshold: int = 7,  # semitones (perfect 5th)
                 duration_effect: float = 0.1,
                 micropause_ms: float = 15.0):
        super().__init__(config)
        self.leap_threshold = leap_threshold
        self.duration_effect = duration_effect
        self.micropause_ms = micropause_ms

    def apply_duration(self, note, features: dict) -> float:
        if not self.enabled:
            return 1.0

        interval = features.get('interval_to_next', 0)
        if abs(interval) >= self.leap_threshold:
            if interval > 0:  # Upward leap
                return 1.0 - self.k * self.duration_effect  # Shorten
            else:  # Downward leap
                return 1.0 + self.k * self.duration_effect  # Lengthen

        return 1.0

    def apply_timing(self, note, features: dict) -> float:
        """Add micropause after landing from a large leap."""
        if not self.enabled:
            return 0.0

        interval_from_prev = features.get('interval_from_prev', 0)
        if abs(interval_from_prev) >= self.leap_threshold:
            return self.k * self.micropause_ms / 1000

        return 0.0
```

**HumanizationConfig è¨­å®š**ï¼š
```python
leap: RuleConfig = field(default_factory=lambda: RuleConfig(
    k=1.0, k_range=(0.5, 1.5)
))
leap_threshold_semitones: int = 7
leap_duration_effect: float = 0.1
leap_micropause_ms: float = 15.0
```

---

### `src/audio/humanize/rules/repetition.py` â­ æ–°å¢ (KTH)

**è·è²¬**ï¼šå¯¦ä½œé‡è¤‡éŸ³è¦å‰‡

**KTH å®šç¾©**ï¼š*Repetition-articulation-dro: Micropause for repeated notes.*

**åŒ…å«**ï¼š
```python
class RepetitionRule(Rule):
    """
    Repetition handling: add micropause between repeated notes.

    Prevents "machine gun" effect on repeated notes.
    """

    def __init__(self, config: RuleConfig,
                 micropause_ms: float = 20.0):
        super().__init__(config)
        self.micropause_ms = micropause_ms

    def apply_duration(self, note, features: dict) -> float:
        """Shorten repeated notes slightly."""
        if not self.enabled:
            return 1.0

        if features.get('is_repeated_note', False):
            return 1.0 - self.k * 0.1  # -10% duration

        return 1.0

    def apply_timing(self, note, features: dict) -> float:
        """Slight delay on repeated notes."""
        if not self.enabled:
            return 0.0

        if features.get('is_repeated_note', False):
            # Small random variation to avoid mechanical feel
            return self.k * self.micropause_ms / 1000

        return 0.0
```

---

### `src/audio/humanize/rules/safety.py` â­ æ–°å¢ (Gemini å»ºè­°)

**è·è²¬**ï¼šå®‰å…¨è¦å‰‡ + å…¨åŸŸæ­£è¦åŒ–

**åŒ…å«å…©å€‹å…ƒä»¶**ï¼š

```python
class SocialDurationCareRule(Rule):
    """
    Social-duration-care: auto-lengthen very short notes.

    Prevents notes from being too short to hear.
    KTH principle: "care for the listener"
    """

    def __init__(self, config: RuleConfig,
                 min_duration_ms: float = 50.0):
        super().__init__(config)
        self.min_duration_ms = min_duration_ms

    def apply_duration(self, note, features: dict) -> float:
        if not self.enabled:
            return 1.0

        note_duration_ms = note.duration * 1000
        if note_duration_ms < self.min_duration_ms:
            # Extend to minimum audible duration
            target_ratio = self.min_duration_ms / note_duration_ms
            return 1.0 + self.k * (target_ratio - 1.0)

        return 1.0


class GlobalNormalizer:
    """
    Global velocity normalization / soft limiting.

    Prevents "smashing piano" when multiple rules stack up.
    Applied as post-processing after all rules.
    """

    def __init__(self,
                 target_rms_velocity: int = 70,
                 max_velocity: int = 115,
                 soft_clip_threshold: int = 100):
        self.target_rms_velocity = target_rms_velocity
        self.max_velocity = max_velocity
        self.soft_clip_threshold = soft_clip_threshold

    def normalize(self, velocities: np.ndarray) -> np.ndarray:
        """Apply global normalization and soft clipping."""
        # 1. RMS normalization (optional)
        # current_rms = np.sqrt(np.mean(velocities ** 2))
        # scale = self.target_rms_velocity / current_rms
        # velocities = velocities * scale

        # 2. Soft clipping for peaks
        # Use tanh-style soft clip above threshold
        above_threshold = velocities > self.soft_clip_threshold
        if np.any(above_threshold):
            excess = velocities[above_threshold] - self.soft_clip_threshold
            max_excess = self.max_velocity - self.soft_clip_threshold
            # Soft clip: compress excess into remaining headroom
            compressed = max_excess * np.tanh(excess / max_excess)
            velocities[above_threshold] = self.soft_clip_threshold + compressed

        # 3. Hard clip as safety
        velocities = np.clip(velocities, 1, 127)

        return velocities.astype(int)
```

**HumanizationConfig è¨­å®š**ï¼š
```python
social_duration_care: RuleConfig = field(default_factory=lambda: RuleConfig(
    k=1.0, k_range=(0.8, 1.2)
))
min_audible_duration_ms: float = 50.0

# Global normalizer settings
normalize_velocity: bool = True
target_rms_velocity: int = 70
max_velocity: int = 115
soft_clip_threshold: int = 100
```

---

### `src/audio/humanize/rules/final_ritard.py`

**è·è²¬**ï¼šå¯¦ä½œ Final-ritard è¦å‰‡ï¼ˆçµå°¾æ¼¸æ…¢ï¼‰

**å…¬å¼**ï¼š`tempo_ratio = 1 - k Ã— sqrt(position_in_final_section)`

**åŒ…å«**ï¼š
```python
class FinalRitardRule(Rule):
    """Final-ritard: gradual slowdown at the end (runner stopping model)."""

    def __init__(self, config: RuleConfig, start_position: float = 0.9):
        super().__init__(config)
        self.start_position = start_position

    def apply_timing(self, note, features: dict) -> float:
        piece_pos = features.get('piece_position', 0.0)  # 0-1
        if piece_pos < self.start_position:
            return 0.0
        # Position within final section (0 to 1)
        final_pos = (piece_pos - self.start_position) / (1 - self.start_position)
        # Cumulative delay based on sqrt model
        return self.k * 0.5 * np.sqrt(final_pos)  # Max 0.5s delay at end
```

---

### `src/audio/humanize/rules/rubato.py` â­ æ–°å¢

**è·è²¬**ï¼šå¯¦ä½œæ¨‚å¥ç´š Rubatoï¼ˆé€Ÿåº¦è®ŠåŒ–ï¼‰

**KTH Phrase-arch tempo è¦å‰‡**ï¼šæ¨‚å¥é–‹å§‹æ…¢ â†’ ä¸­é–“å¿« â†’ çµå°¾æ¼¸æ…¢

**å…¬å¼**ï¼š
```
tempo_ratio = 1 + k Ã— rubato_curve(phrase_position)
rubato_curve: é–‹å§‹ -0.1, ä¸­é–“ +0.1, çµå°¾ -0.15
```

**åŒ…å«**ï¼š
```python
class PhraseRubatoRule(Rule):
    """
    Phrase-level rubato: tempo varies within phrases.

    Based on KTH Phrase-arch rule (tempo component):
    - Slower at phrase start (settling in)
    - Faster in middle (forward momentum)
    - Slower at phrase end (breathing, punctuation)
    """

    def __init__(self, config: RuleConfig, peak_position: float = 0.6):
        super().__init__(config)
        self.peak_position = peak_position

    def apply_timing(self, note, features: dict) -> float:
        """Return cumulative timing offset based on phrase position."""
        if not self.enabled:
            return 0.0

        phrase_pos = features.get('phrase_position')  # 0-1 within phrase
        if phrase_pos is None:
            return 0.0

        # Compute local tempo ratio
        # Asymmetric: slower start, faster middle, slowest end
        if phrase_pos < self.peak_position:
            # Accelerating phase: -0.1 â†’ +0.1
            ratio = -0.1 + 0.2 * (phrase_pos / self.peak_position)
        else:
            # Decelerating phase: +0.1 â†’ -0.15
            decel_pos = (phrase_pos - self.peak_position) / (1 - self.peak_position)
            ratio = 0.1 - 0.25 * decel_pos

        # Convert tempo ratio to timing offset
        # Negative ratio (slower) = positive timing offset (later)
        beat_duration = features.get('beat_duration', 0.5)  # seconds
        return -self.k * ratio * beat_duration * 0.5  # Scale down effect


class BeatRubatoRule(Rule):
    """
    Beat-level micro rubato: subtle push/pull on beat boundaries.

    Creates "breathing" quality by slightly delaying or rushing beats.
    """

    def __init__(self, config: RuleConfig):
        super().__init__(config)
        self.rng = None  # Set by engine

    def apply_timing(self, note, features: dict) -> float:
        if not self.enabled:
            return 0.0

        # Stronger effect on downbeats
        beat_strength = features.get('beat_strength', 0.5)  # 0-1

        # Random but correlated across nearby notes
        base_rubato = self.rng.normal(0, 0.02)  # Â±20ms base

        # Downbeats tend to be slightly late (weight)
        if features.get('is_downbeat', False):
            base_rubato += 0.01  # +10ms tendency

        return self.k * base_rubato * beat_strength
```

**èˆ‡ dynamics çš„è€¦åˆ**ï¼ˆKTH åŸå‰‡ï¼‰ï¼š
- Phrase-arch åŒæ™‚å½±éŸ¿ velocity å’Œ tempo
- æ¨‚å¥ä¸­é–“è¼ƒå¿«**ä¸”**è¼ƒå¤§è²
- é€™æ˜¯çœŸå¯¦æ¼”å¥çš„ç‰¹å¾µ

---

### `src/audio/humanize/rules/dynamics_tempo.py` â­ æ–°å¢

**è·è²¬**ï¼šDynamics marking â†’ tempo èª¿æ•´ï¼ˆvelocity-tempo è€¦åˆï¼‰

**KTH åŸç†**ï¼šäººé¡æ¼”å¥ä¸­ï¼Œdynamics å’Œ tempo é«˜åº¦ç›¸é—œï¼š
- crescendo æ™‚é€šå¸¸æœƒ accelerando
- diminuendo æ™‚é€šå¸¸æœƒ ritardando
- sf/accent æœƒæœ‰ agogic accentï¼ˆå¾®å¾®å»¶é²ï¼‰

**åŒ…å«**ï¼š
```python
class CrescendoTempoRule(Rule):
    """
    Crescendo/diminuendo affects tempo.

    Based on KTH research: dynamics and tempo are coupled.
    - Crescendo â†’ slight accelerando
    - Diminuendo â†’ slight ritardando
    """

    def __init__(self, config: RuleConfig, max_tempo_change: float = 0.1):
        super().__init__(config)
        self.max_tempo_change = max_tempo_change  # 10% max

    def apply_timing(self, note, features: dict) -> float:
        if not self.enabled:
            return 0.0

        # loudness_incr from partitura's loudness_direction_basis
        loudness_change = features.get('loudness_incr', 0) - features.get('loudness_decr', 0)

        # Positive = crescendo = faster = negative timing offset
        # Effect scales with k
        tempo_ratio = self.k * self.max_tempo_change * loudness_change
        beat_duration = features.get('beat_duration', 0.5)

        return -tempo_ratio * beat_duration  # Negative = earlier


class AgogicAccentRule(Rule):
    """
    Agogic accent: accented notes are slightly delayed.

    Creates emphasis through timing, not just velocity.
    """

    def __init__(self, config: RuleConfig, delay_ms: float = 20):
        super().__init__(config)
        self.delay_ms = delay_ms

    def apply_timing(self, note, features: dict) -> float:
        if not self.enabled:
            return 0.0

        # Check for accent marking from articulation_basis
        has_accent = features.get('accent', 0) > 0.5
        has_sf = features.get('sf', 0) > 0.5 or features.get('sfz', 0) > 0.5

        if has_accent or has_sf:
            return self.k * self.delay_ms / 1000

        return 0.0
```

**HumanizationConfig è¨­å®š**ï¼š
```python
# Dynamics-tempo coupling
crescendo_tempo: RuleConfig = field(default_factory=lambda: RuleConfig(
    k=1.0, k_range=(0.3, 1.5)
))
crescendo_tempo_max_change: float = 0.1  # Â±10% tempo

# Agogic accent
agogic_accent: RuleConfig = field(default_factory=lambda: RuleConfig(
    k=1.0, k_range=(0.5, 1.5)
))
agogic_delay_ms: float = 20.0
```

---

### `src/audio/humanize/rules/articulation_tempo.py` â­ æ–°å¢

**è·è²¬**ï¼šArticulation â†’ tempo å¾®èª¿

**åŒ…å«**ï¼š
```python
class ArticulationTempoRule(Rule):
    """
    Articulation affects local tempo feel.

    - Legato passages: slightly slower, more connected
    - Staccato passages: can feel slightly faster
    - Tenuto: slight lengthening and delay of next note
    """

    def __init__(self, config: RuleConfig):
        super().__init__(config)

    def apply_timing(self, note, features: dict) -> float:
        if not self.enabled:
            return 0.0

        # Tenuto: hold slightly longer, delay next
        if features.get('tenuto', False):
            return self.k * 0.015  # +15ms

        # Legato context: slightly broader timing
        if features.get('in_slur', False):
            return self.k * 0.005  # +5ms tendency

        return 0.0
```

**HumanizationConfig è¨­å®š**ï¼š
```python
articulation_tempo: RuleConfig = field(default_factory=lambda: RuleConfig(
    k=1.0, k_range=(0.5, 1.5)
))

---

### Rubato åœ¨ HumanizationConfig ä¸­çš„è¨­å®š

```python
# åœ¨ HumanizationConfig ä¸­æ–°å¢ï¼š

# Phrase rubato: tempo variation within phrases
phrase_rubato: RuleConfig = field(default_factory=lambda: RuleConfig(
    k=1.0, k_range=(0.5, 1.5)
))

# Beat rubato: micro tempo fluctuations
beat_rubato: RuleConfig = field(default_factory=lambda: RuleConfig(
    k=0.8, k_range=(0.3, 1.2)  # Default slightly less than 1
))
```

---

### `src/audio/humanize/rules/fermata.py` â­ æ–°å¢

**è·è²¬**ï¼šå¯¦ä½œ Fermataï¼ˆå»¶é•·è¨˜è™Ÿï¼‰è™•ç†

**åƒè€ƒ**ï¼šBasisMixer çš„ `fermata_basis`

**åŒ…å«**ï¼š
```python
class FermataRule(Rule):
    """
    Fermata: extend note duration and add pause after.

    Typical fermata effect:
    - Note duration Ã— 1.5-2.5 (depends on context)
    - Small pause (breath) after fermata note
    - Often accompanied by ritardando leading into fermata
    """

    def __init__(self, config: RuleConfig,
                 duration_multiplier: float = 2.0,
                 pause_beats: float = 0.5):
        super().__init__(config)
        self.duration_multiplier = duration_multiplier
        self.pause_beats = pause_beats

    def apply_duration(self, note, features: dict) -> float:
        if not self.enabled:
            return 1.0
        if not features.get('has_fermata', False):
            return 1.0
        # Extend duration
        return 1.0 + self.k * (self.duration_multiplier - 1.0)

    def apply_timing(self, note, features: dict) -> float:
        """Add pause AFTER fermata note (affects subsequent notes)."""
        if features.get('after_fermata', False):
            beat_duration = features.get('beat_duration', 0.5)
            return self.k * self.pause_beats * beat_duration
        return 0.0
```

**HumanizationConfig è¨­å®š**ï¼š
```python
fermata: RuleConfig = field(default_factory=lambda: RuleConfig(
    k=1.0, k_range=(0.7, 1.5)
))
fermata_duration_multiplier: float = 2.0
fermata_pause_beats: float = 0.5
```

---

### `src/audio/humanize/rules/ornaments.py` â­ æ–°å¢

**è·è²¬**ï¼šè™•ç†è£é£¾éŸ³ï¼ˆGrace notes, Trills, Mordentsï¼‰

**åŒ…å«**ï¼š
```python
class GraceNoteRule(Rule):
    """
    Grace notes: play before the beat, steal time from previous note.

    Two styles:
    - Acciaccatura (æ–œç·š): very short, "crushed" into main note
    - Appoggiatura (ç„¡æ–œç·š): longer, more expressive
    """

    def __init__(self, config: RuleConfig,
                 acciaccatura_ms: float = 50,
                 appoggiatura_ratio: float = 0.25):
        super().__init__(config)
        self.acciaccatura_ms = acciaccatura_ms
        self.appoggiatura_ratio = appoggiatura_ratio

    def compute_grace_timing(self, grace_note, main_note, features: dict) -> dict:
        """
        Compute timing for grace note.

        Returns dict with:
        - grace_onset: when grace note starts
        - grace_duration: how long grace note lasts
        - main_onset_shift: how much main note is delayed (usually 0)
        """
        if features.get('is_acciaccatura', True):
            # Short, before the beat
            grace_duration = self.k * self.acciaccatura_ms / 1000
            grace_onset = main_note.onset - grace_duration
            return {
                'grace_onset': grace_onset,
                'grace_duration': grace_duration,
                'main_onset_shift': 0
            }
        else:
            # Appoggiatura: takes time from main note
            beat_duration = features.get('beat_duration', 0.5)
            grace_duration = self.k * self.appoggiatura_ratio * beat_duration
            return {
                'grace_onset': main_note.onset,
                'grace_duration': grace_duration,
                'main_onset_shift': grace_duration
            }


class TrillRule(Rule):
    """
    Trills: rapid alternation between main note and upper neighbor.

    Parameters:
    - trill_speed: notes per second (typically 6-12)
    - start_on_upper: whether to start on upper note (Baroque) or main (Romantic)
    """

    def __init__(self, config: RuleConfig,
                 trill_speed: float = 8.0,
                 start_on_upper: bool = False):
        super().__init__(config)
        self.trill_speed = trill_speed
        self.start_on_upper = start_on_upper

    def expand_trill(self, note, features: dict) -> List[dict]:
        """
        Expand a trilled note into alternating pitches.

        Returns list of {pitch, onset, duration, velocity} dicts.
        """
        if not features.get('has_trill', False):
            return [{'pitch': note.pitch, 'onset': note.onset,
                     'duration': note.duration, 'velocity': note.velocity}]

        notes = []
        current_time = note.onset
        end_time = note.onset + note.duration
        note_duration = 1.0 / (self.k * self.trill_speed)

        upper_pitch = note.pitch + features.get('trill_interval', 2)  # Usually whole/half step
        is_upper = self.start_on_upper

        while current_time < end_time - note_duration * 0.5:
            pitch = upper_pitch if is_upper else note.pitch
            dur = min(note_duration, end_time - current_time)
            notes.append({
                'pitch': pitch,
                'onset': current_time,
                'duration': dur,
                'velocity': note.velocity - (5 if is_upper else 0)  # Upper slightly softer
            })
            current_time += note_duration
            is_upper = not is_upper

        return notes


class MordentRule(Rule):
    """Mordent: quick alternation (main-upper-main or main-lower-main)."""

    def expand_mordent(self, note, features: dict) -> List[dict]:
        """Expand mordent into 3 notes."""
        if not features.get('has_mordent', False):
            return [{'pitch': note.pitch, 'onset': note.onset,
                     'duration': note.duration, 'velocity': note.velocity}]

        mordent_duration = self.k * 0.08  # ~80ms total for ornament
        single_note_dur = mordent_duration / 3

        is_upper = features.get('mordent_type', 'upper') == 'upper'
        aux_pitch = note.pitch + (2 if is_upper else -2)

        return [
            {'pitch': note.pitch, 'onset': note.onset,
             'duration': single_note_dur, 'velocity': note.velocity},
            {'pitch': aux_pitch, 'onset': note.onset + single_note_dur,
             'duration': single_note_dur, 'velocity': note.velocity - 5},
            {'pitch': note.pitch, 'onset': note.onset + 2 * single_note_dur,
             'duration': note.duration - 2 * single_note_dur, 'velocity': note.velocity},
        ]
```

**HumanizationConfig è¨­å®š**ï¼š
```python
grace_note: RuleConfig = field(default_factory=lambda: RuleConfig(
    k=1.0, k_range=(0.7, 1.3)
))
acciaccatura_ms: float = 50.0
appoggiatura_ratio: float = 0.25

trill: RuleConfig = field(default_factory=lambda: RuleConfig(
    k=1.0, k_range=(0.8, 1.2)
))
trill_speed: float = 8.0  # notes per second
trill_start_on_upper: bool = False

mordent: RuleConfig = field(default_factory=lambda: RuleConfig(
    k=1.0, k_range=(0.8, 1.2)
))
```

---

### `src/audio/humanize/rules/tempo.py` â­ æ–°å¢

**è·è²¬**ï¼šè§£æ Tempo markingï¼Œè¨­å®šåŸºç¤é€Ÿåº¦

**åŒ…å«**ï¼š
```python
# Standard tempo ranges (BPM)
TEMPO_MARKINGS = {
    # Very slow
    'grave': (20, 40),
    'largo': (40, 60),
    'lento': (45, 60),
    'larghetto': (60, 66),
    'adagio': (66, 76),

    # Slow
    'andante': (76, 108),
    'andantino': (80, 108),

    # Moderate
    'moderato': (108, 120),
    'allegretto': (112, 120),

    # Fast
    'allegro': (120, 168),
    'vivace': (168, 176),
    'presto': (168, 200),
    'prestissimo': (200, 240),
}


class TempoInterpreter:
    """
    Interpret tempo markings from score.

    NOT a Rule (no k value) - this sets the BASE tempo.
    """

    def __init__(self, default_bpm: float = 108):
        self.default_bpm = default_bpm

    def get_base_tempo(self, marking: Optional[str], rng=None) -> float:
        """
        Get base BPM from tempo marking.

        If rng provided, randomly sample within the marking's range.
        """
        if marking is None:
            return self.default_bpm

        marking_lower = marking.lower().strip()

        # Check for explicit BPM (e.g., "â™©= 120")
        if '=' in marking_lower:
            try:
                bpm = float(marking_lower.split('=')[1].strip())
                return bpm
            except:
                pass

        # Check known markings
        for name, (low, high) in TEMPO_MARKINGS.items():
            if name in marking_lower:
                if rng is not None:
                    return rng.uniform(low, high)
                return (low + high) / 2

        return self.default_bpm

    def get_tempo_from_score(self, part) -> float:
        """Extract tempo marking from partitura Part."""
        # Look for tempo indications in the score
        for direction in part.iter_all(partitura.score.Tempo):
            return direction.bpm
        for direction in part.iter_all(partitura.score.Direction):
            if hasattr(direction, 'text'):
                bpm = self.get_base_tempo(direction.text)
                if bpm != self.default_bpm:
                    return bpm
        return self.default_bpm
```

**ä½¿ç”¨æ–¹å¼**ï¼ˆåœ¨ Engine ä¸­ï¼‰ï¼š
```python
class HumanizationEngine:
    def __init__(self, config: HumanizationConfig):
        self.config = config
        self.tempo_interpreter = TempoInterpreter(
            default_bpm=config.default_bpm
        )

    def humanize(self, score_path: str, output_path: str, ...):
        part = load_score(score_path)

        # Get base tempo from score markings
        base_bpm = self.tempo_interpreter.get_tempo_from_score(part)

        # Can also randomize within marking range for augmentation
        if self.config.randomize_tempo:
            base_bpm = self.tempo_interpreter.get_base_tempo(
                marking, rng=self.rng
            )
```

**HumanizationConfig è¨­å®š**ï¼š
```python
default_bpm: float = 108  # BasisMixer default
randomize_tempo: bool = True  # Sample within marking range
tempo_variation_range: Tuple[float, float] = (0.9, 1.1)  # Â±10% variation
```

---

### `src/audio/humanize/rules/timing.py`

**è·è²¬**ï¼šMicro-timing jitter + chord asynchrony

**åŒ…å«**ï¼š
```python
class MicroTimingRule(Rule):
    """Micro-timing: small random timing variations."""

    def __init__(self, config: RuleConfig, std_ms: float = 15.0):
        super().__init__(config)
        self.std_ms = std_ms
        self.rng = None  # Set by engine

    def apply_timing(self, note, features: dict) -> float:
        jitter = self.rng.normal(0, self.std_ms / 1000)
        return self.k * jitter


class ChordAsyncRule(Rule):
    """Chord asynchrony: melody leads bass."""

    def __init__(self, config: RuleConfig, lead_ms: float = 25.0):
        super().__init__(config)
        self.lead_ms = lead_ms

    def apply_timing(self, note, features: dict) -> float:
        if features.get('is_melody', False):
            return -self.k * self.lead_ms / 1000  # Negative = earlier
        return 0.0
```

---

### `src/audio/humanize/rules/articulation.py`

**è·è²¬**ï¼šStaccato/legato duration èª¿æ•´

**åŒ…å«**ï¼š
```python
class StaccatoRule(Rule):
    """Staccato: shorten note duration."""

    def apply_duration(self, note, features: dict) -> float:
        if features.get('articulation') == 'staccato':
            return 1.0 - self.k * 0.5  # 50% shorter at k=1
        return 1.0


class LegatoRule(Rule):
    """Legato: overlap notes slightly."""

    def __init__(self, config: RuleConfig, overlap_ms: float = 30.0):
        super().__init__(config)
        self.overlap_ms = overlap_ms

    def apply_duration(self, note, features: dict) -> float:
        if features.get('in_slur', False):
            # Extend by overlap amount
            base_dur = note.duration
            overlap_ratio = (self.k * self.overlap_ms / 1000) / base_dur
            return 1.0 + overlap_ratio
        return 1.0
```

---

### `src/audio/humanize/rules/pedal.py`

**è·è²¬**ï¼šè‡ªå‹•è¸æ¿ç”Ÿæˆ

**åŒ…å«**ï¼š
```python
class AutoPedalRule(Rule):
    """Auto pedal: syncopated pedaling based on harmony changes."""

    def __init__(self, config: RuleConfig,
                 lift_before_ms: float = 30.0,
                 press_after_ms: float = 20.0):
        super().__init__(config)
        self.lift_before_ms = lift_before_ms
        self.press_after_ms = press_after_ms

    def generate_pedal_events(self, notes, features_list) -> List[PedalEvent]:
        """Generate CC64 events for sustain pedal."""
        events = []
        # Detect harmony changes from features
        # Lift pedal before change, press after
        ...
        return events
```

---

### `src/audio/humanize/engine.py`

**è·è²¬**ï¼šæ•´åˆæ‰€æœ‰è¦å‰‡ï¼ŒåŸ·è¡Œ humanization pipeline

**åŒ…å«**ï¼š
```python
class HumanizationEngine:
    """Main engine that applies all KTH rules to generate humanized MIDI."""

    def __init__(self, config: HumanizationConfig):
        self.config = config
        self._init_rules()

    def _init_rules(self):
        """Initialize all rule instances from config."""
        cfg = self.config

        # Velocity rules
        self.velocity_rules = [
            HighLoudRule(cfg.high_loud),
            PhraseArchRule(cfg.phrase_arch, cfg.phrase_peak_position),
            DurationContrastRule(cfg.duration_contrast),
            MelodicChargeRule(cfg.melodic_charge, cfg.non_chord_tone_boost_dB, cfg.leading_tone_boost_dB),
        ]

        # Timing rules
        self.timing_rules = [
            PhraseRubatoRule(cfg.phrase_rubato, cfg.phrase_peak_position),
            BeatRubatoRule(cfg.beat_rubato),
            FinalRitardRule(cfg.final_ritard, cfg.final_ritard_start),
            MicroTimingRule(cfg.timing_jitter, cfg.timing_jitter_std_ms),
            ChordAsyncRule(cfg.chord_async, cfg.melody_lead_base_ms),
            FermataRule(cfg.fermata, cfg.fermata_duration_multiplier, cfg.fermata_pause_beats),
            # Velocity-tempo coupling
            CrescendoTempoRule(cfg.crescendo_tempo, cfg.crescendo_tempo_max_change),
            AgogicAccentRule(cfg.agogic_accent, cfg.agogic_delay_ms),
            ArticulationTempoRule(cfg.articulation_tempo),
            # Phrasing
            PunctuationRule(cfg.punctuation, cfg.micropause_ms, cfg.phrase_end_shorten_ratio),
            LeapRule(cfg.leap, cfg.leap_threshold_semitones, cfg.leap_duration_effect, cfg.leap_micropause_ms),
            RepetitionRule(cfg.repetition),
        ]

        # Safety rules
        self.social_care = SocialDurationCareRule(cfg.social_duration_care, cfg.min_audible_duration_ms)
        self.normalizer = GlobalNormalizer(
            cfg.target_rms_velocity, cfg.max_velocity, cfg.soft_clip_threshold
        )

        # Articulation rules
        self.articulation_rules = [
            StaccatoRule(cfg.staccato),
            LegatoRule(cfg.legato, cfg.legato_overlap_base_ms),
        ]

        # Ornament handlers
        self.ornament_rules = [
            GraceNoteRule(cfg.grace_note, cfg.acciaccatura_ms, cfg.appoggiatura_ratio),
            TrillRule(cfg.trill, cfg.trill_speed, cfg.trill_start_on_upper),
            MordentRule(cfg.mordent),
        ]

        # Special
        self.pedal_rule = AutoPedalRule(cfg.pedal, cfg.pedal_lift_before_ms, cfg.pedal_press_after_ms)
        self.tempo_interpreter = TempoInterpreter(cfg.default_bpm)

    def humanize(self, score_path: str, output_path: str, format: str = 'kern'):
        """Main entry point: Score â†’ Humanized MIDI."""
        # 1. Load score with partitura
        # 2. Extract features (basis functions)
        # 3. Apply all rules (additive in dB space)
        # 4. Generate pedal events
        # 5. Write MIDI with mido

    def _extract_features(self, part) -> List[dict]:
        """Extract per-note features using partitura basis functions."""

    def _compute_final_velocity(self, note, features: dict) -> int:
        """Apply all velocity rules (additive in dB)."""
        base_dB = velocity_to_dB(self._get_base_velocity(note, features))
        for rule in self.rules:
            base_dB += rule.apply_velocity(note, features)
        return dB_to_velocity(base_dB)
```

**ä¾è³´**ï¼š`partitura`, `mido`, æ‰€æœ‰ rule æ¨¡çµ„

---

### `src/audio/humanize/presets.py`

**è·è²¬**ï¼šé è¨­é¢¨æ ¼è¨­å®š

**åŒ…å«**ï¼š
```python
# Romantic style: more expressive
ROMANTIC = HumanizationConfig(
    high_loud=RuleConfig(k=1.2, k_range=(0.8, 1.5)),
    phrase_arch=RuleConfig(k=1.3, k_range=(0.8, 1.8)),
    timing_jitter=RuleConfig(k=1.2, k_range=(0.8, 1.5)),
    final_ritard=RuleConfig(k=1.5, k_range=(1.0, 2.0)),
    ...
)

# Classical style: more restrained
CLASSICAL = HumanizationConfig(
    high_loud=RuleConfig(k=0.8, k_range=(0.5, 1.0)),
    phrase_arch=RuleConfig(k=0.8, k_range=(0.5, 1.2)),
    timing_jitter=RuleConfig(k=0.7, k_range=(0.5, 1.0)),
    final_ritard=RuleConfig(k=0.8, k_range=(0.5, 1.2)),
    ...
)

# Balanced (default)
BALANCED = HumanizationConfig()  # All k=1.0
```

---

## æ ¸å¿ƒé¡åˆ¥è¨­è¨ˆï¼šk å€¼ç³»çµ±

### è¨­è¨ˆå“²å­¸

æ¯æ¢è¦å‰‡éƒ½æœ‰ä¸€å€‹ **k å€¼**æ§åˆ¶å¼·åº¦ï¼Œé€™æ˜¯ data augmentation çš„æ ¸å¿ƒï¼š

```
æœ€çµ‚æ•ˆæœ = Î£ (è¦å‰‡_i çš„åŸºç¤æ•ˆæœ Ã— k_i)
```

- éš¨æ©ŸåŒ– k å€¼ â†’ ç”¢ç”Ÿä¸åŒã€Œæ¼”å¥é¢¨æ ¼ã€çš„è¨“ç·´è³‡æ–™
- k å€¼ç¯„åœå®šç¾©äº†åˆç†çš„éŸ³æ¨‚è¡¨é”ç©ºé–“
- æ‰€æœ‰è¦å‰‡æ•ˆæœç–ŠåŠ ï¼ˆadditiveï¼‰ï¼Œä¸æœƒäº’ç›¸è¦†è“‹

### RuleConfigï¼ˆå–®ä¸€è¦å‰‡è¨­å®šï¼‰

```python
@dataclass
class RuleConfig:
    """Configuration for a single KTH-style rule."""
    k: float = 1.0              # Current k value
    k_range: Tuple[float, float] = (0.5, 1.5)  # Randomization range
    enabled: bool = True        # Toggle rule on/off

    def randomize(self, rng: np.random.Generator) -> 'RuleConfig':
        """Return new config with randomized k within range."""
        new_k = rng.uniform(self.k_range[0], self.k_range[1])
        return RuleConfig(k=new_k, k_range=self.k_range, enabled=self.enabled)
```

### HumanizationConfigï¼ˆå®Œæ•´è¨­å®šï¼‰

```python
@dataclass
class HumanizationConfig:
    """
    KTH-style humanization configuration with k-value system.

    All effects are ADDITIVE (ç–ŠåŠ ), referenced to:
    - 0 dB = MIDI velocity 64 (KTH standard)
    - BasisMixer default velocity = 55
    """

    # === Global Settings ===
    reference_velocity: int = 64      # 0 dB reference point
    default_velocity: int = 55        # BasisMixer default (mf)

    # === Dynamics Rules ===
    # Dynamic marking â†’ velocity mapping (not affected by k)
    dynamics_map: Dict[str, int] = field(default_factory=lambda: {
        'ppp': 20, 'pp': 35, 'p': 50,
        'mp': 60, 'mf': 70,
        'f': 85, 'ff': 100, 'fff': 115,
        'sf': 95, 'sfz': 100, 'fp': 85,
    })

    # === KTH Rules (each with k value) ===

    # High-loud: pitch è¶Šé«˜ â†’ è¶Šå¤§è²
    # Effect: +k Ã— 0.5 dB per semitone above middle C
    high_loud: RuleConfig = field(default_factory=lambda: RuleConfig(
        k=1.0, k_range=(0.3, 1.5)
    ))

    # Phrase-arch: æ¨‚å¥ä¸­é–“å¼·ï¼Œå…©ç«¯å¼±
    # Effect: Â±k Ã— 6 dB at phrase peak/boundaries
    phrase_arch: RuleConfig = field(default_factory=lambda: RuleConfig(
        k=1.0, k_range=(0.5, 1.5)
    ))
    phrase_peak_position: float = 0.6  # 0-1, where peak occurs

    # Duration-contrast: é•·éŸ³æ›´é•·æ›´å¤§è²
    # Effect: Â±k Ã— 3 dB based on relative duration
    duration_contrast: RuleConfig = field(default_factory=lambda: RuleConfig(
        k=1.0, k_range=(0.5, 1.5)
    ))

    # Melodic-charge: å¼·èª¿æ—‹å¾‹å¼µåŠ›éŸ³
    # Effect: +k Ã— 4 dB for non-chord tones
    melodic_charge: RuleConfig = field(default_factory=lambda: RuleConfig(
        k=1.0, k_range=(0.0, 1.5)
    ))

    # Final-ritard: çµå°¾æ¼¸æ…¢
    # Effect: tempo Ã— (1 - k Ã— sqrt(position)) in final 10%
    final_ritard: RuleConfig = field(default_factory=lambda: RuleConfig(
        k=1.0, k_range=(0.5, 2.0)
    ))
    final_ritard_start: float = 0.9   # Start position (0-1)

    # === Timing Rules ===

    # Micro-timing jitter
    # Effect: Â±k Ã— 15ms gaussian noise
    timing_jitter: RuleConfig = field(default_factory=lambda: RuleConfig(
        k=1.0, k_range=(0.5, 1.5)
    ))
    timing_jitter_std_ms: float = 15.0  # Base std in ms

    # Chord asynchrony (melody lead)
    # Effect: melody leads by k Ã— 25ms
    chord_async: RuleConfig = field(default_factory=lambda: RuleConfig(
        k=1.0, k_range=(0.5, 2.0)
    ))
    melody_lead_base_ms: float = 25.0

    # Metrical accent
    # Effect: +k Ã— 5 velocity on downbeats
    metrical_accent: RuleConfig = field(default_factory=lambda: RuleConfig(
        k=1.0, k_range=(0.5, 1.5)
    ))
    downbeat_boost_base: int = 5

    # === Articulation Rules ===

    # Staccato shortening
    # Effect: duration Ã— (1 - k Ã— 0.5) for staccato notes
    staccato: RuleConfig = field(default_factory=lambda: RuleConfig(
        k=1.0, k_range=(0.7, 1.3)
    ))

    # Legato overlap
    # Effect: +k Ã— 30ms overlap for legato phrases
    legato: RuleConfig = field(default_factory=lambda: RuleConfig(
        k=1.0, k_range=(0.5, 1.5)
    ))
    legato_overlap_base_ms: float = 30.0

    # === Pedal Settings ===
    pedal_enabled: bool = True
    pedal_lift_before_ms: float = 30.0   # Lift before chord change
    pedal_press_after_ms: float = 20.0   # Press after new chord

    # === Methods ===

    def randomize(self, seed: Optional[int] = None) -> 'HumanizationConfig':
        """
        Create a new config with all k values randomized within their ranges.
        This is the core of data augmentation diversity.
        """
        rng = np.random.default_rng(seed)

        return HumanizationConfig(
            # Keep global settings
            reference_velocity=self.reference_velocity,
            default_velocity=self.default_velocity,
            dynamics_map=self.dynamics_map.copy(),

            # Randomize all rule k values
            high_loud=self.high_loud.randomize(rng),
            phrase_arch=self.phrase_arch.randomize(rng),
            phrase_peak_position=rng.uniform(0.5, 0.7),
            duration_contrast=self.duration_contrast.randomize(rng),
            melodic_charge=self.melodic_charge.randomize(rng),
            final_ritard=self.final_ritard.randomize(rng),
            final_ritard_start=rng.uniform(0.85, 0.95),
            timing_jitter=self.timing_jitter.randomize(rng),
            timing_jitter_std_ms=self.timing_jitter_std_ms,
            chord_async=self.chord_async.randomize(rng),
            melody_lead_base_ms=self.melody_lead_base_ms,
            metrical_accent=self.metrical_accent.randomize(rng),
            downbeat_boost_base=self.downbeat_boost_base,
            staccato=self.staccato.randomize(rng),
            legato=self.legato.randomize(rng),
            legato_overlap_base_ms=self.legato_overlap_base_ms,
            pedal_enabled=self.pedal_enabled,
            pedal_lift_before_ms=self.pedal_lift_before_ms,
            pedal_press_after_ms=self.pedal_press_after_ms,
        )

    def to_dict(self) -> Dict:
        """Export config for logging/reproducibility."""
        return {
            'high_loud_k': self.high_loud.k,
            'phrase_arch_k': self.phrase_arch.k,
            'duration_contrast_k': self.duration_contrast.k,
            'melodic_charge_k': self.melodic_charge.k,
            'final_ritard_k': self.final_ritard.k,
            'timing_jitter_k': self.timing_jitter.k,
            'chord_async_k': self.chord_async.k,
            'metrical_accent_k': self.metrical_accent.k,
            'staccato_k': self.staccato.k,
            'legato_k': self.legato.k,
        }
```

### k å€¼éš¨æ©ŸåŒ–ç¯„ä¾‹

```python
# ç”¢ç”Ÿ 4 å€‹ä¸åŒé¢¨æ ¼çš„ humanized ç‰ˆæœ¬
base_config = HumanizationConfig()

for i in range(4):
    config = base_config.randomize(seed=i)
    print(f"Version {i}: {config.to_dict()}")

# Output example:
# Version 0: {'high_loud_k': 0.82, 'phrase_arch_k': 1.23, ...}
# Version 1: {'high_loud_k': 1.31, 'phrase_arch_k': 0.67, ...}
# Version 2: {'high_loud_k': 0.45, 'phrase_arch_k': 1.45, ...}
# Version 3: {'high_loud_k': 1.12, 'phrase_arch_k': 0.89, ...}
```

### HumanizationEngine

```python
class HumanizationEngine:
    """
    Apply KTH-style humanization rules with k-value system.

    All velocity effects are computed in dB, then converted to MIDI velocity.
    Effects are additive: final_dB = base_dB + Î£(rule_effect_i Ã— k_i)
    """

    def __init__(self, config: HumanizationConfig):
        self.config = config

    def humanize_from_score(
        self,
        score_path: str,
        output_midi_path: str,
        format: str = 'kern'
    ) -> MidiFile:
        """Main entry point: Score â†’ Humanized MIDI."""
        ...

    def _apply_velocity_rules(self, note, features) -> int:
        """
        Apply all velocity-affecting rules (additive in dB space).

        Returns: final MIDI velocity (1-127)
        """
        cfg = self.config

        # Start from dynamic marking or default
        base_vel = self._get_dynamic_velocity(note)
        base_dB = self._velocity_to_dB(base_vel)

        # Add rule effects (all in dB)
        dB_delta = 0.0

        # High-loud: +0.5 dB per semitone above C4
        if cfg.high_loud.enabled:
            semitones_above_c4 = note.pitch - 60
            dB_delta += cfg.high_loud.k * 0.5 * semitones_above_c4

        # Phrase-arch: based on position in phrase
        if cfg.phrase_arch.enabled and features.get('phrase_position') is not None:
            arch_effect = self._compute_phrase_arch(features['phrase_position'])
            dB_delta += cfg.phrase_arch.k * arch_effect

        # Duration-contrast: long notes louder
        if cfg.duration_contrast.enabled:
            dur_effect = self._compute_duration_effect(note, features)
            dB_delta += cfg.duration_contrast.k * dur_effect

        # ... more rules ...

        # Convert back to velocity
        final_dB = base_dB + dB_delta
        return self._dB_to_velocity(final_dB)

    def _velocity_to_dB(self, velocity: int) -> float:
        """Convert MIDI velocity to dB (0 dB = velocity 64)."""
        # KTH uses polynomial approximation
        return 20 * np.log10(velocity / 64 + 1e-6)

    def _dB_to_velocity(self, dB: float) -> int:
        """Convert dB back to MIDI velocity, clamped to 1-127."""
        velocity = int(64 * (10 ** (dB / 20)))
        return max(1, min(127, velocity))
```

---

## Partitura Basis Functions å°æ‡‰è¡¨

### å¾æ¨‚è­œè®€å–çš„ Features

æ¯å€‹è¦å‰‡éœ€è¦çš„ features éƒ½ä¾†è‡ª partitura çš„ `make_note_feats()`ï¼š

| è¦å‰‡ | éœ€è¦çš„ Feature | Partitura Basis |
|------|----------------|-----------------|
| HighLoud | `pitch` | ç›´æ¥å¾ note å–å¾— |
| PhraseArch | `phrase_position`, `slur_incr`, `slur_decr` | `slur_basis` |
| DurationContrast | `duration`, `relative_duration` | `duration_basis` |
| **MelodicCharge** | `is_non_chord_tone`, `is_leading_tone` | éœ€è¦å’Œè²åˆ†æ (music21) |
| **CrescendoTempo** | `loudness_incr`, `loudness_decr` | `loudness_direction_basis` |
| **AgogicAccent** | `accent`, `sf`, `sfz` | `articulation_basis`, `loudness_direction_basis` |
| **ArticulationTempo** | `tenuto`, `in_slur` | `articulation_basis`, `slur_basis` |
| **Punctuation** | `is_phrase_end`, `is_phrase_start` | `slur_basis` + è¨ˆç®— |
| **Leap** | `interval_to_next`, `interval_from_prev` | è¨ˆç®—ç›¸é„°éŸ³é«˜å·® |
| **Repetition** | `is_repeated_note` | è¨ˆç®—ç›¸é„°éŸ³é«˜ç›¸åŒ |
| Staccato | `staccato` | `articulation_basis` |
| Fermata | `fermata` | `fermata_basis` |
| MicroTiming | `beat_strength`, `is_downbeat` | `metrical_basis` |
| GraceNote | `is_grace`, `is_acciaccatura` | `grace_basis` |
| Trill | `has_trill`, `trill_interval` | éœ€è¦é¡å¤–è§£æ |

### Engine ä¸­çš„ Feature æå–

```python
class HumanizationEngine:
    # éœ€è¦çš„æ‰€æœ‰ basis functions
    REQUIRED_BASIS_FUNCTIONS = [
        'polynomial_pitch_basis',      # pitch, pitchÂ², pitchÂ³
        'loudness_direction_basis',    # p, f, mf, cresc, dim, sf
        'articulation_basis',          # accent, staccato, tenuto
        'duration_basis',              # note duration
        'slur_basis',                  # slur_incr, slur_decr (phrase)
        'fermata_basis',               # fermata
        'grace_basis',                 # grace notes
        'metrical_basis',              # beat positions
    ]

    def _extract_features(self, part) -> List[dict]:
        """Extract per-note features using partitura."""
        import partitura.musicanalysis as ma

        # Get basis function matrix
        basis_matrix, basis_names = ma.make_note_feats(
            part, self.REQUIRED_BASIS_FUNCTIONS
        )

        # Convert to per-note feature dicts
        features_list = []
        for i, note in enumerate(part.notes_tied):
            features = {
                name: basis_matrix[i, j]
                for j, name in enumerate(basis_names)
            }
            # Add computed features
            features['phrase_position'] = self._compute_phrase_position(i, features)
            features['piece_position'] = i / len(part.notes_tied)
            features['beat_duration'] = 60 / self.base_bpm
            features_list.append(features)

        return features_list
```

### Dynamics Marking ç›´æ¥è®€å–

```python
def _get_base_velocity(self, note, features: dict) -> int:
    """Get base velocity from dynamics marking."""
    # Check loudness_direction_basis features
    for marking, velocity in self.config.dynamics_map.items():
        feature_name = f'loudness_direction_basis.{marking}'
        if features.get(feature_name, 0) > 0.5:
            return velocity

    return self.config.default_velocity
```

---

## å¯é‡ç¾æ€§ (Reproducibility)

### Metadata Logging

æ¯å€‹ humanized MIDI éƒ½è¦è¨˜éŒ„å®Œæ•´è¨­å®šï¼Œç¢ºä¿å¯é‡ç¾ï¼š

```python
@dataclass
class HumanizationMetadata:
    """Metadata for reproducibility."""
    source_file: str           # Original kern/midi path
    version: int               # Augmentation version (0-3)
    seed: int                  # Random seed
    timestamp: str             # ISO format
    k_values: Dict[str, float] # All k values
    base_config: Dict          # HumanizationConfig settings
    soundfont: Optional[str]   # If rendered
    partitura_version: str
    humanize_version: str      # Module version


class HumanizationEngine:
    def humanize(self, ...) -> Tuple[MidiFile, HumanizationMetadata]:
        ...
        metadata = HumanizationMetadata(
            source_file=str(score_path),
            version=version_idx,
            seed=self.config.seed,
            timestamp=datetime.now().isoformat(),
            k_values=self.config.to_dict(),
            base_config=self.config.to_full_dict(),
            partitura_version=pt.__version__,
            humanize_version=__version__,
        )
        return midi, metadata
```

**å­˜æ”¾æ–¹å¼**ï¼šåŒå `.json` sidecar file

```
output/
â”œâ”€â”€ chopin_op10_no1_v0.mid
â”œâ”€â”€ chopin_op10_no1_v0.json    # â† Metadata
â”œâ”€â”€ chopin_op10_no1_v1.mid
â”œâ”€â”€ chopin_op10_no1_v1.json
...
```

**é‡ç¾ç‰¹å®šç‰ˆæœ¬**ï¼š
```python
# From metadata JSON
metadata = json.load(open('chopin_op10_no1_v2.json'))
config = HumanizationConfig.from_dict(metadata['base_config'])
config.apply_k_values(metadata['k_values'])
# Guaranteed identical output
```

---

## éŒ¯èª¤è™•ç† & Graceful Degradation

**åŸå‰‡**ï¼šå–®é¦–å¤±æ•—ä¸æ‡‰æ‹–ç´¯æ•´å€‹ pipeline

### Rule-level Fallback

æ¯å€‹ rule éƒ½æ‡‰è©²èƒ½å®¹éŒ¯ï¼š

```python
class Rule(ABC):
    def apply_velocity(self, note, features: dict) -> float:
        try:
            return self._apply_velocity_impl(note, features)
        except Exception as e:
            logging.warning(f"{self.__class__.__name__} failed: {e}")
            return 0.0  # No effect on failure
```

### Feature-level Fallback

ç¼ºå°‘æŸäº› features æ™‚ä½¿ç”¨é è¨­å€¼ï¼š

```python
def _extract_features(self, part):
    # Try full basis functions
    try:
        basis_matrix, names = make_note_feats(part, self.REQUIRED_BASIS)
    except Exception as e:
        logging.warning(f"Full basis failed, using critical only: {e}")
        basis_matrix, names = make_note_feats(part, self.CRITICAL_BASES)

    # Fill missing with defaults
    for features in features_list:
        features.setdefault('fermata', 0.0)
        features.setdefault('slur_incr', 0.0)
        features.setdefault('beat_strength', 0.5)
        ...
```

### File-level Fallback

å–®é¦–è™•ç†å¤±æ•—æ™‚è¨˜éŒ„ä¸¦ç¹¼çºŒï¼š

```python
def process_batch(kern_paths):
    results = []
    failed = []

    for kern in kern_paths:
        try:
            result = humanize(kern)
            results.append(result)
        except Exception as e:
            logging.error(f"Failed to process {kern}: {e}")
            failed.append((kern, str(e)))
            continue  # Don't stop the whole batch

    # Save failed list for debugging
    save_failed_list(failed, 'humanize_failures.txt')
    return results
```

---

## Valid/Test è™•ç†

**æ±ºç­–**ï¼šTrain å…ˆåšï¼ŒValid/Test æš«ç·©

| Split | è™•ç†æ–¹å¼ | ç†ç”± |
|-------|----------|------|
| **Train** | âœ… Humanize (4 versions, randomize k) | éœ€è¦å¤šæ¨£æ€§ |
| **Valid** | â¸ï¸ æš«ä¸è™•ç† | éœ€è¦è¨­è¨ˆ evaluation ç­–ç•¥ |
| **Test** | â¸ï¸ æš«ä¸è™•ç† | éœ€è¦è¨­è¨ˆ evaluation ç­–ç•¥ |

**å¾ŒçºŒè€ƒé‡**ï¼š
- Valid/Test æ˜¯å¦ä¹Ÿè¦ humanizeï¼Ÿ
- å¦‚æœæ˜¯ï¼Œç”¨ fixed k=1.0 é‚„æ˜¯ä¹Ÿ randomizeï¼Ÿ
- è©•ä¼°æŒ‡æ¨™å¦‚ä½•è¨­è¨ˆï¼Ÿ

é€™äº›å•é¡Œç­‰ Train è·‘å®Œã€æ¨¡å‹è¨“ç·´å¾Œå†æ±ºå®šã€‚

---

## Data Augmentation æ•´åˆ

### k å€¼ç³»çµ± Ã— å¤š SoundFont = è¨“ç·´å¤šæ¨£æ€§

```python
def generate_augmented_versions(
    kern_path: str,
    output_dir: str,
    n_versions: int = 4,
    soundfonts: List[str] = SOUNDFONTS,
) -> List[str]:
    """
    Generate multiple humanized versions of a score.

    Total outputs = n_versions Ã— len(soundfonts)
    Example: 4 k-value variants Ã— 4 soundfonts = 16 audio files per score
    """
    base_config = HumanizationConfig()
    engine = HumanizationEngine(base_config)
    outputs = []

    for version_idx in range(n_versions):
        # Randomize k values for this version
        config = base_config.randomize(seed=version_idx)
        engine.config = config

        # Generate humanized MIDI
        midi_path = output_dir / f"{kern_path.stem}_v{version_idx}.mid"
        engine.humanize_from_score(kern_path, midi_path)

        # Log k values for reproducibility
        log_config(midi_path, config.to_dict())

        # Render with each soundfont
        for sf_name in soundfonts:
            wav_path = output_dir / f"{kern_path.stem}_v{version_idx}~{sf_name}.wav"
            render_midi_to_audio(midi_path, wav_path, soundfont=sf_name)
            outputs.append(wav_path)

    return outputs
```

### èˆ‡ clef-piano-base çš„å·®ç•°

| é¢å‘ | clef-piano-base | clef-piano-full |
|------|-----------------|-----------------|
| Velocity | Uniform (90) | k å€¼ç³»çµ± humanization |
| Timing | æ©Ÿæ¢°åŒ– | Micro-timing + ritardando |
| Articulation | ç„¡ | Staccato/legato rules |
| Pedal | ç„¡ | Auto pedaling |
| å¤šæ¨£æ€§ä¾†æº | åƒ… SoundFont | k å€¼ Ã— SoundFont |
| ç”¨é€” | Zeng baseline æ¯”è¼ƒ | ä¸»è¦è¨“ç·´è³‡æ–™ |

---

## å»¶ä¼¸è¦å‰‡ï¼ˆclef-solo / clef-tutti ç”¨ï¼‰

ä»¥ä¸‹è¦å‰‡å° **Piano Solo ä¸éœ€è¦**ï¼Œä½†å°å…¶ä»–æ¨‚å™¨æœ‰ç”¨ï¼š

### Intonation è¦å‰‡ï¼ˆéå›ºå®šéŸ³é«˜æ¨‚å™¨ï¼‰

| è¦å‰‡ | èªªæ˜ | é©ç”¨æ¨‚å™¨ |
|------|------|----------|
| **High-sharp** | é«˜éŸ³å¾®å‡ | å¼¦æ¨‚ã€ç®¡æ¨‚ |
| **Melodic-intonation** | æ—‹å¾‹å¾‹ï¼šå°éŸ³å‡é«˜ | å¼¦æ¨‚ |
| **Harmonic-intonation** | å’Œè²å¾‹ï¼šç´”å¾‹èª¿æ•´ | å¼¦æ¨‚åˆå¥ |

### Ensemble è¦å‰‡ï¼ˆå¤šæ¨‚å™¨ï¼‰

| è¦å‰‡ | èªªæ˜ | é©ç”¨æƒ…å¢ƒ |
|------|------|----------|
| **Bar-sync** | å°ç¯€ç·šå°é½Š | ç®¡å¼¦æ¨‚ |
| **Melodic-sync** | æ—‹å¾‹è²éƒ¨åŒæ­¥ | å®¤å…§æ¨‚ |
| **Ensemble-swing** | åˆå¥ swing æ¯”ä¾‹ | Jazz ensemble |

### å…¶ä»–å¯é¸è¦å‰‡

| è¦å‰‡ | èªªæ˜ | å„ªå…ˆç´š |
|------|------|--------|
| **Faster-uphill** | ä¸Šè¡ŒåŠ é€Ÿ | âšª å¯é¸ |
| **InÃ©gales** | Baroque swing | âšª å¤å…¸ä¸éœ€è¦ |
| **Harmonic-charge** | é é›¢èª¿æ€§çš„å’Œå¼¦å¼·èª¿ | âšª éœ€è¦è¤‡é›œå’Œè²åˆ†æ |

é€™äº›è¦å‰‡çš„ spec å¯ä»¥åœ¨å¯¦ä½œ clef-solo/tutti æ™‚å†è£œä¸Šã€‚

---



## å¯¦ä½œå„ªå…ˆé †åº

### Phase 1: Core Infrastructure
1. `config.py` â€” RuleConfig + HumanizationConfig + randomize()
2. `convert.py` â€” dB â†” velocity è½‰æ›
3. `rules/base.py` â€” Rule æŠ½è±¡åŸºåº•é¡åˆ¥
4. `rules/tempo.py` â€” TempoInterpreter (è§£æ Allegro/Andante â†’ BPM)

### Phase 2: Velocity Rules
5. `rules/high_loud.py` â€” Pitch â†’ velocity
6. `rules/phrase_arch.py` â€” Phrase position â†’ velocity
7. `rules/duration_contrast.py` â€” Duration â†’ velocity
8. `rules/melodic_charge.py` â€” éå’Œå¼¦éŸ³/å°éŸ³ â†’ velocity (éœ€å’Œè²åˆ†æ)

### Phase 3: Core Timing Rules
9. `rules/rubato.py` â€” PhraseRubatoRule + BeatRubatoRule
10. `rules/final_ritard.py` â€” çµå°¾æ¼¸æ…¢
11. `rules/timing.py` â€” MicroTiming + ChordAsync
12. `rules/fermata.py` â€” Fermata å»¶é•· + pause
13. `rules/dynamics_tempo.py` â€” CrescendoTempo + AgogicAccent
14. `rules/articulation_tempo.py` â€” Tenuto/legato timing
15. `rules/punctuation.py` â€” æ¨‚å¥é–“ micropause (æ°£å£)
16. `rules/leap.py` â€” å¤§è·³ timing/duration
17. `rules/repetition.py` â€” é‡è¤‡éŸ³ micropause

### Phase 4: Articulation + Ornaments
18. `rules/articulation.py` â€” Staccato/legato duration
19. `rules/ornaments.py` â€” GraceNote, Trill, Mordent

### Phase 5: Safety + Special
20. `rules/safety.py` â€” SocialDurationCare + GlobalNormalizer
21. `rules/pedal.py` â€” Auto pedaling (CC64)

### Phase 6: Integration
22. `engine.py` â€” HumanizationEngine æ•´åˆæ‰€æœ‰è¦å‰‡
23. `presets.py` â€” romantic/classical/balanced é è¨­

### Phase 7: Pipeline + CLI
24. æ•´åˆåˆ° `prepare_piano_full.py`
25. `cli.py` â€” CLI å·¥å…·ï¼ˆå¯ç¨ç«‹ä½¿ç”¨ï¼‰
26. ç«¯åˆ°ç«¯æ¸¬è©¦ + è½è¦ºé©—è­‰

---

## ä¾è³´ç®¡ç†

### æ–°å¢ä¾è³´

```toml
[tool.poetry.dependencies]
partitura = "^1.4.0"
```

### ç¾æœ‰ä¾è³´ï¼ˆå·²åœ¨ pyproject.tomlï¼‰

| åº« | ç”¨é€” |
|------|------|
| **mido** | åº•å±¤ MIDI æ“ä½œï¼ˆtick-levelï¼‰ï¼Œç²¾ç¢ºæ§åˆ¶ note_on/note_off/CC |
| **music21** | Score è§£æã€Kern è½‰æ› |
| **midi2audio** | FluidSynth åŒ…è£ï¼ŒMIDIâ†’WAV |

### mido èªªæ˜

mido æ˜¯ Python MIDI åº«ï¼Œæ¯” pretty_midi æ›´åº•å±¤ï¼š
- ç›´æ¥æ“ä½œ MIDI events (note_on, note_off, control_change)
- tick-level timing ç²¾åº¦
- æ”¯æ´ä¿®æ”¹ç¾æœ‰ MIDI æª”æ¡ˆ

```python
import mido
from mido import MidiFile, MidiTrack, Message

# è®€å– MIDI
midi = MidiFile('input.mid')

# ä¿®æ”¹ note velocity
for track in midi.tracks:
    for msg in track:
        if msg.type == 'note_on':
            msg.velocity = new_velocity

# åŠ å…¥è¸æ¿ CC64
track.append(Message('control_change', control=64, value=127, time=0))
```

### Partitura æ•´åˆæ–¹å¼

```python
import partitura as pt
from partitura.musicanalysis import make_note_feats

# è¼‰å…¥ Kernï¼ˆpartitura æ”¯æ´ï¼‰
score = pt.load_kern('score.krn')
part = score[0]

# æå– BasisMixer basis functions
features, names = make_note_feats(part, [
    'polynomial_pitch_basis',
    'loudness_direction_basis',
    'articulation_basis',
    'slur_basis',
    'metrical_basis',
])

# features shape: (n_notes, n_features)
# ç”¨æ–¼ rule-based humanization
```

### Partitura vs Music21 åˆ†å·¥

| åŠŸèƒ½ | å·¥å…· | ç†ç”± |
|------|------|------|
| Kern è®€å¯« | converter21 (music21) | å·²æ•´åˆ |
| Dynamics/Articulation è§£æ | partitura | æ›´è±å¯Œçš„ basis functions |
| Phrase detection | partitura (slur_basis) | slur_incr/slur_decr |
| MIDI è¼¸å‡º | mido | tick-level ç²¾ç¢ºæ§åˆ¶ |
| Audio æ¸²æŸ“ | FluidSynth | å·²æ•´åˆ |

---

## KTH Director Musices å®˜æ–¹åƒæ•¸

**ä¾†æº**: `docs/kth_director_musices_rules.pdf`

### K å€¼ç³»çµ±
- æ‰€æœ‰è¦å‰‡æœ‰ global quantity parameter **k** (é è¨­ = 1.0)
- è¦å‰‡æ•ˆæœæ˜¯ **additive**ï¼ˆç–ŠåŠ ï¼‰
- 0 dB = MIDI velocity 64ï¼ˆæ¨™æº–åŒ–åƒè€ƒé»ï¼‰

### è¦å‰‡åˆ—è¡¨ï¼ˆTable 1 from PDFï¼‰

| è¦å‰‡ | å½±éŸ¿è®Šæ•¸ | èªªæ˜ |
|------|----------|------|
| **High-loud** | sl | pitch è¶Šé«˜ â†’ è¶Šå¤§è² |
| **Melodic-charge** | sl dr va | å¼·èª¿é é›¢å’Œå¼¦æ ¹éŸ³çš„éŸ³ç¬¦ |
| **Duration-contrast** | dr sl | é•·éŸ³æ›´é•·æ›´å¤§è²ï¼ŒçŸ­éŸ³æ›´çŸ­æ›´å°è² |
| **Score-legato-art** | dro | legato éŸ³ç¬¦é‡ç–Šä¸‹ä¸€å€‹éŸ³ç¬¦ |
| **Score-staccato-art** | dro | staccato éŸ³ç¬¦åŠ  micropause |
| **Phrase-arch** | dr sl | å¼§å½¢ tempoï¼šæ…¢â†’å¿«â†’æ¼¸æ…¢ï¼›sl èˆ‡ tempo è€¦åˆ |
| **Final-ritard** | dr | çµå°¾æ¼¸æ…¢ï¼ˆæ¨¡å‹ä¾†è‡ªè·‘æ­¥è€…åœæ­¢ï¼‰ |
| **Punctuation** | dr dro | è‡ªå‹•æ¨™è¨˜æ¨‚å¥ï¼Œæœ€å¾ŒéŸ³ç¬¦å»¶é•· + micropause |

### è¦å‰‡ Palette é è¨­å€¼ï¼ˆFigure 4ï¼‰

| è¦å‰‡ | k | é¡å¤–åƒæ•¸ |
|------|---|----------|
| High-loud | 1.0 | â€” |
| Melodic-Charge | 1.0 | :Amp 1 :Dur 1 |
| Harmonic-Charge | 1.0 | :Amp 1 :Dur 0.5 |
| Duration-Contrast | 1.0 | :Amp 0 |
| Phrase-Arch | 1.0 | :Phlevel 5 :Amp 1 :Turn 0.5 |
| Final-Ritard | 1.0 | q=3 |
| Phrase-Articulation | 1.0 | :Phlevel 5 :Subphonelevel 6 |

### dB â†” MIDI Velocity è½‰æ›
- éç·šæ€§ï¼ˆ3 æ¬¡å¤šé …å¼ï¼‰
- 0 dB = velocity 64
- -15 dB â‰ˆ velocity 18-35ï¼ˆè¦–åˆæˆå™¨ï¼‰
- +10 dB â‰ˆ velocity 100-110

---

## BasisMixer å®˜æ–¹åƒæ•¸

**ä¾†æº**: `docs/basismixer_src/`

### DEFAULT_VALUES (`utils/rendering.py`)

```python
DEFAULT_VALUES = {
    'velocity': 55,           # â‰ˆ 43% (mf)
    'velocity_trend': 55,
    'velocity_dev': 0,
    'beat_period': 0.556,     # 108 BPM
    'timing': 0,              # ç„¡åå·®
    'articulation_log': 0,    # 100% duration
}
```

### RENDER_CONFIG åƒæ•¸ç¯„åœ

| åƒæ•¸ | min | max | èªªæ˜ |
|------|-----|-----|------|
| velocity | 20/127 (â‰ˆ16) | 108/127 (â‰ˆ85) | MIDI velocity |
| timing | -0.05 | +0.05 | Â±50ms |
| articulation_log | -1.25 | +1.5 | duration ratio 0.42-2.83 |
| beat_period_ratio | 1/3 | 3 | tempo è®ŠåŒ–ç¯„åœ |

### Vienna 4x22 Basis Functions (`config.json`)

ç”¨æ–¼ `partitura.musicanalysis.make_note_feats()`:

```python
BASIS_FUNCTIONS = [
    # Pitch
    'polynomial_pitch_basis',    # pitch, pitchÂ², pitchÂ³

    # Dynamics
    'loudness_direction_basis',  # mf, pp, p, f, sf, ff, incr, decr

    # Tempo
    'tempo_direction_basis',     # andante, lento, decr

    # Articulation
    'articulation_basis',        # accent, staccato

    # Duration & Phrase
    'duration_basis',            # note duration
    'slur_basis',                # slur_incr, slur_decr (phrase boundary)

    # Special
    'fermata_basis',             # fermata
    'grace_basis',               # grace notes

    # Metrical
    'metrical_basis',            # beat positions (3/4, 6/8, 2/4)
]
```

---

## é—œéµæª”æ¡ˆ

| æª”æ¡ˆ | ç”¨é€” |
|------|------|
| `src/clef/piano/prepare_zeng_pretrain.py` | åƒè€ƒç¾æœ‰ pipeline |
| `src/audio/zeng_synthesis.py` | MIDIProcess åƒè€ƒ |
| `src/score/clean_kern.py` | `strip_non_kern_spines(keep_dynam=True)` |
| `src/preprocessing/humsyn_processor.py` | `keep_dynam` å·²è¨­å®š |
| `configs/clef_piano_full.yaml` | è¨­å®šæª”ï¼ˆéœ€æ“´å±• humanizationï¼‰ |

---

## æ¸¬è©¦ç­–ç•¥

1. **å–®å…ƒæ¸¬è©¦**ï¼šæ¯å€‹è¦å‰‡æ¨¡çµ„ç¨ç«‹æ¸¬è©¦
2. **è½è¦ºæ¸¬è©¦**ï¼šA/B æ¯”è¼ƒ humanized vs uniform velocity
3. **åƒæ•¸é©—è­‰**ï¼šç¢ºä¿ randomization ç¯„åœåˆç†
4. **ç«¯åˆ°ç«¯**ï¼š10 é¦–æ›²ç›®å®Œæ•´ pipeline æ¸¬è©¦

---

## å·²ä¸‹è¼‰çš„åƒè€ƒè³‡æ–™

| æª”æ¡ˆ | ä¾†æº | èªªæ˜ |
|------|------|------|
| `docs/kth_director_musices_rules.pdf` | KTH | å®Œæ•´è¦å‰‡ç³»çµ±èªªæ˜ |
| `docs/kth_overview_rules_2006.pdf` | Advances in Cognitive Psychology | 2006 overview paper |
| `docs/basismixer_src/` | CPJKU GitHub | BasisMixer å®Œæ•´åŸå§‹ç¢¼ |

### é—œéµåƒè€ƒæª”æ¡ˆ
- `docs/basismixer_src/utils/rendering.py` â€” DEFAULT_VALUES, RENDER_CONFIG
- `docs/basismixer_src/performance_codec.py` â€” ç·¨ç¢¼/è§£ç¢¼é‚è¼¯
- `docs/basismixer_src/assets/sample_models/vienna_4x22_*/config.json` â€” basis functions åˆ—è¡¨

---

## é©—è­‰æ­¥é©Ÿ

å®Œæˆå¾ŒåŸ·è¡Œï¼š
```bash
# 1. å®‰è£æ–°ä¾è³´
poetry add partitura

# 2. å–®å…ƒæ¸¬è©¦
pytest tests/test_humanize*.py -v

# 3. ç«¯åˆ°ç«¯æ¸¬è©¦
python -m src.clef.piano.prepare_piano_full --phase 2 --limit 10

# 4. è½è¦ºé©—è­‰
# æ¯”è¼ƒ output/audio/*.wav å’Œ baseline
```

---

## ç¸½çµ

**ç›®æ¨™**ï¼šç‚º clef-piano-full å¯¦ä½œ rule-based MIDI humanizationï¼ŒæŠŠ DAW æ¬åˆ° Pythonã€‚

**æ ¸å¿ƒå“²å­¸**ï¼šEnlightenment, not Noise â€” æ‰€æœ‰è½‰æ›éƒ½æ˜¯éŸ³æ¨‚çŸ¥è­˜çš„ç·¨ç¢¼ã€‚

**æŠ€è¡“å †ç–Š**ï¼š
- **Score è§£æ**: partitura (basis functions) + music21 (kern I/O)
- **MIDI æ“ä½œ**: mido (tick-level control)
- **Audio æ¸²æŸ“**: FluidSynth (å·²æ•´åˆ)

**åƒæ•¸ä¾†æº**ï¼š
- KTH Director Musices (k å€¼ç³»çµ±)
- BasisMixer (DEFAULT_VALUES, RENDER_CONFIG)

**ä¸æœƒå½±éŸ¿**ï¼šclef-piano-baseï¼ˆå®Œå…¨åˆ†é›¢çš„ pipelineï¼‰

---

## CLI å·¥å…·ï¼ˆBonusï¼‰

### `src/audio/humanize/cli.py`

**ç”¨é€”**ï¼šç¨ç«‹ CLI å·¥å…·ï¼Œå¯ç”¨æ–¼å€‹äººéŸ³æ¨‚è£½ä½œï¼ˆLogic Pro X workflowï¼‰

```python
"""
CLI tool for MIDI humanization.

Usage:
    python -m src.audio.humanize.cli input.mid output.mid --style romantic
    python -m src.audio.humanize.cli score.krn output.mid --format kern
"""

import click
from pathlib import Path
from .engine import HumanizationEngine
from .config import HumanizationConfig
from .presets import ROMANTIC, CLASSICAL, BAROQUE, BALANCED

PRESETS = {
    'romantic': ROMANTIC,
    'classical': CLASSICAL,
    'baroque': BAROQUE,
    'balanced': BALANCED,
}

@click.command()
@click.argument('input_file', type=click.Path(exists=True))
@click.argument('output_midi', type=click.Path())
@click.option('--style', type=click.Choice(list(PRESETS.keys())), default='balanced',
              help='Performance style preset')
@click.option('--format', type=click.Choice(['midi', 'kern', 'musicxml']), default='midi',
              help='Input file format')
@click.option('--randomize/--no-randomize', default=True,
              help='Randomize k values for variation')
@click.option('--seed', type=int, default=None,
              help='Random seed for reproducibility')
@click.option('--render', type=click.Path(),
              help='Also render to audio (requires soundfont path)')
@click.option('--verbose', '-v', is_flag=True,
              help='Print k values and processing info')
def main(input_file, output_midi, style, format, randomize, seed, render, verbose):
    """
    Humanize a MIDI file or score with KTH performance rules.

    Examples:
        humanize song.mid humanized.mid --style romantic
        humanize score.krn output.mid --format kern --seed 42
    """
    config = PRESETS[style]

    if randomize:
        config = config.randomize(seed=seed)

    if verbose:
        click.echo(f"Style: {style}")
        click.echo(f"k values: {config.to_dict()}")

    engine = HumanizationEngine(config)

    if format == 'midi':
        engine.humanize_midi(input_file, output_midi)
    else:
        engine.humanize_from_score(input_file, output_midi, format=format)

    click.echo(f"âœ“ Humanized: {input_file} â†’ {output_midi}")

    if render:
        from ..zeng_synthesis import MIDIProcess
        wav_path = Path(output_midi).with_suffix('.wav')
        # Render using FluidSynth
        click.echo(f"âœ“ Rendered: {wav_path}")


if __name__ == '__main__':
    main()
```

### ä½¿ç”¨ç¯„ä¾‹

```bash
# åŸºæœ¬ç”¨æ³•ï¼šMIDI â†’ Humanized MIDI
python -m src.audio.humanize.cli input.mid output.mid

# æŒ‡å®šé¢¨æ ¼
python -m src.audio.humanize.cli input.mid output.mid --style romantic

# å¾ Kern æ ¼å¼è½‰æ›
python -m src.audio.humanize.cli score.krn output.mid --format kern

# å›ºå®š seed ç¢ºä¿å¯é‡ç¾
python -m src.audio.humanize.cli input.mid output.mid --seed 42 --verbose

# åŒæ™‚ render æˆ audio
python -m src.audio.humanize.cli input.mid output.mid --render /path/to/soundfont.sf2
```

### Logic Pro X å·¥ä½œæµç¨‹

```
1. åœ¨ Logic å¯«å¥½ MIDI
2. Export æˆ .mid
3. Terminal: python -m src.audio.humanize.cli song.mid humanized.mid --style romantic
4. æŠŠ humanized.mid æ‹–å› Logic
5. ç”¨ Logic çš„éŸ³æºæ’­æ”¾

æˆ–è€…ç›´æ¥ render:
python -m src.audio.humanize.cli song.mid humanized.mid --render ~/soundfonts/piano.sf2
# ç”¢å‡º humanized.wavï¼Œç›´æ¥ import åˆ° Logic
```
