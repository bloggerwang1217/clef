# clef-piano-base Training Configuration
# =======================================
#
# ISMIR 2026 target: Serial encoder (Octopus → Flow → Swin pitch space)
#
# Architecture: bio-inspired serial pipeline
# - Octopus2D = CN octopus cells (cross-frequency onset detection)
# - Flow = IC harmonic integration (mel → pitch space)
# - Swin = A1 cortex (multi-scale 2D on pitch space)

# =============================================================================
# Seeds
# =============================================================================
seed:
  data_augmentation: 0
  training: 1234

# =============================================================================
# Model Architecture
# =============================================================================
model:
  name: "clef-piano-base"

  # Encoder: Swin V2 (frozen core, selective fine-tune)
  swin_model: "microsoft/swinv2-tiny-patch4-window8-256"
  swin_dims: [96, 192, 384, 768]
  freeze_encoder: true
  # Selective unfreeze: adapt input/merge/position to pitch space (~1.6M / 27.6M = 5.8%)
  # - patch_embed: Conv2d(3,96,4,4) learns to see pitch-space patches (4.9K)
  # - position_bias: Continuous relative position MLP learns harmonic intervals (89K)
  # - downsample: Patch merging Linear learns to combine harmonic features (1.55M)
  swin_unfreeze: ["patch_embed", "position_bias", "downsample"]
  swin_lr_scale: 0.1  # 0.1x base_lr for pretrained params

  # Serial encoder: Swin eats Flow output (pitch space)
  swin_on_pitch_space: true
  swin_pool_strides: [1, 1, 1, 1]  # Flow already reduced T, no extra pool needed

  # Octopus2D (CN octopus cells: cross-frequency onset detection)
  use_octopus: true
  octopus_freq_kernel: 31      # ~4 harmonics span
  octopus_time_kernel: 3       # onset transient (30ms)
  octopus_channels: 32         # different onset pattern detectors
  octopus_time_pool_stride: 2  # T → T/2
  octopus_freq_pool_stride: 4  # 128 mels → 32 freq bins

  # HarmonizingFlow (IC harmonic integration: mel → pitch space)
  use_flow: true
  n_harmonics: 6
  flow_pool_stride: 4          # T → T/4
  use_temporal_cnn: false      # Serial mode: no CNN, Octopus provides onset

  # Deformable Attention (CLEF)
  d_model: 512
  n_heads: 8
  n_levels: 6                  # Octopus + Flow + S0-S3
  ff_dim: 2048
  dropout: 0.1

  n_points_freq: 2
  n_points_time: 2
  freq_offset_scale: 1.0
  time_offset_scale: 1.0

  use_time_prior: true
  use_freq_prior: true
  n_freq_groups: 4
  refine_range: 0.1

  # Time prior: RoPE + delta_t
  rope_base: 10000.0      # RoPE frequency base (same as SA layers)

  bridge_layers: 2

  # Decoder (2026-02-19: window_ca replaces deformable — robust to imprecise centers)
  # Layer 0: Perceiver (S2+S3 → audio_latent, global harmony context)
  # Layer 1: full_ca (SA + Full MHA on S2+S3: bootstrap temporal/freq grounding via attn CoM)
  # Layer 2, 4, 6: Mamba-only (sequential writing)
  # Layer 3: SA + Window CA (S0+S1: beat position, pitch register — center from L1 CoM)
  # Layer 5: SA + Window CA (L0+L1: onset timing, precise pitch — center from L1 CoM)
  decoder_layer_types: ["perceiver", "full_ca", "mamba_only", "window_ca", "mamba_only", "window_ca", "mamba_only"]
  decoder_layer_ca_levels:
    - null        # perceiver: no CA
    - [4, 5]      # full_ca L1: S2+S3 (full attention, provides CoM for downstream window_ca)
    - null        # mamba_only
    - [2, 3]      # window_ca L3: S0+S1 (dense window, note level — beat, pitch register)
    - null        # mamba_only
    - [0, 1]      # window_ca L5: L0+L1 (dense window, onset+pitch precision)
    - null        # mamba_only

  # Window cross-attention parameters
  # Per-level window sizes (levels 0-3 used by window_ca; levels 4-5 S2/S3 by full_ca only)
  # Level: 0=Octopus(46ms)  1=Flow(93ms)  2=S0(370ms)  3=S1(741ms)
  # Coverage: L0=32×46ms=1.47s  L1=16×93ms=1.49s  L2=8×370ms=2.96s  L3=4×741ms=2.96s
  window_time_frames: [32, 16, 8, 4, 4, 4]
  window_freq_bins: [4, 4, 4, 4, 4, 4]
  window_seq_chunk_size: 10000  # large enough to avoid chunking (peak fwd mem: [B,N_q,K_l,D]~350MB, fine on 24GB)
  mamba_d_state: 128
  mamba_d_conv: 4
  mamba_expand: 2
  decoder_layers: 7
  max_seq_len: 10000
  vocab_size: 271

  label_smoothing: 0.0

# =============================================================================
# Data
# =============================================================================
data:
  datasets:
    - musesyn
    - humsyn

  vocabulary: "zeng_extended"

  audio:
    sample_rate: 16000
    feature: "log_mel"
    n_mels: 128
    n_fft: 2048
    hop_length: 160             # 100 fps
    f_min: 27.5                 # A0
    f_max: 7040.0               # 8 octaves

  chunking:
    enabled: true
    chunk_frames: 24000         # 4 min (primary)
    overlap_frames: 12000       # 2 min overlap
    min_chunk_ratio: 0.5
    # Fallback: if a 4min chunk would exceed max_seq_len tokens, re-chunk at 2min/1min
    fallback_chunk_frames: 12000   # 2 min
    fallback_overlap_frames: 6000  # 1 min overlap

  augmentation:
    transpose:
      enabled: true
    soundfonts:
      - "TimGM6mb.sf2"
      - "FluidR3_GM.sf2"
      - "UprightPianoKW-20220221.sf2"
      - "SalamanderGrandPiano-V3+20200602.sf2"
    loudness_norm:
      target_lufs: -15

# =============================================================================
# Training
# =============================================================================
training:
  distributed:
    enabled: true
    backend: "nccl"
    num_gpus: 2

  precision: "bf16"
  batch_size: 1
  gradient_accumulation_steps: 2
  effective_batch_size: 4

  learning_rate: 2.0e-5
  weight_decay: 0.01
  max_epochs: 50
  warmup_steps: 5000
  gradient_clip: 1.0

  save_every_n_epochs: 10
  save_best: true
  save_last: true
  early_stopping_patience: 5

  wandb:
    enabled: true
    project: "clef-piano-base"
    tags: ["piano", "a2s", "serial-encoder", "rtx3090"]

# =============================================================================
# Paths
# =============================================================================
paths:
  data_dir: "data/datasets"
  output_dir: "data/experiments/clef_piano_base"
  checkpoint_dir: "checkpoints/clef_piano_base"
