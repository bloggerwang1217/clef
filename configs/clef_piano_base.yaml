# clef-piano-base Training Configuration
# =======================================
#
# ISMIR 2026 target: Serial encoder (Octopus → Flow → Swin pitch space)
#
# Architecture: bio-inspired serial pipeline
# - Octopus2D = CN octopus cells (cross-frequency onset detection)
# - Flow = IC harmonic integration (mel → pitch space)
# - Swin = A1 cortex (multi-scale 2D on pitch space)

# =============================================================================
# Seeds
# =============================================================================
seed:
  data_augmentation: 0
  training: 1234

# =============================================================================
# Model Architecture
# =============================================================================
model:
  name: "clef-piano-base"

  # Encoder: Swin V2 (frozen core, selective fine-tune)
  swin_model: "microsoft/swinv2-tiny-patch4-window8-256"
  swin_dims: [96, 192, 384, 768]
  freeze_encoder: true
  # Selective unfreeze: adapt input/merge/position to pitch space (~1.6M / 27.6M = 5.8%)
  # - patch_embed: Conv2d(3,96,4,4) learns to see pitch-space patches (4.9K)
  # - position_bias: Continuous relative position MLP learns harmonic intervals (89K)
  # - downsample: Patch merging Linear learns to combine harmonic features (1.55M)
  swin_unfreeze: ["patch_embed", "position_bias", "downsample"]
  swin_lr_scale: 0.1  # 0.1x base_lr for pretrained params

  # Serial encoder: Swin eats Flow output (pitch space)
  swin_on_pitch_space: true
  swin_pool_strides: [1, 1, 1, 1]  # Flow already reduced T, no extra pool needed

  # Octopus2D (CN octopus cells: cross-frequency onset detection)
  use_octopus: true
  octopus_freq_kernel: 31      # ~4 harmonics span
  octopus_time_kernel: 3       # onset transient (30ms)
  octopus_channels: 32         # different onset pattern detectors
  octopus_time_pool_stride: 2  # T → T/2
  octopus_freq_pool_stride: 4  # 128 mels → 32 freq bins

  # HarmonizingFlow (IC harmonic integration: mel → pitch space)
  use_flow: true
  n_harmonics: 6
  flow_pool_stride: 4          # T → T/4
  use_temporal_cnn: false      # Serial mode: no CNN, Octopus provides onset

  # Deformable Attention (CLEF)
  d_model: 512
  n_heads: 8
  n_levels: 6                  # Octopus + Flow + S0-S3
  ff_dim: 2048
  dropout: 0.1

  n_points_freq: 2
  n_points_time: 2
  freq_offset_scale: 1.0
  time_offset_scale: 1.0

  use_time_prior: true
  use_freq_prior: true
  n_freq_groups: 4
  refine_range: 0.1

  # Time prior: RoPE + delta_t
  rope_base: 10000.0      # RoPE frequency base (same as SA layers)

  bridge_layers: 2

  # Decoder (2026-02-20 v7: bar-token-aware full attention, no Perceiver)
  # Layer 0: window_ca (SA + Bar Full-Attn on onset_1d + Window CA on S2+S3)
  #   L1: window_ca — bar full-attn on onset_1d → bar_center; Window CA on S2+S3 (full freq)
  #   L2: mamba_only — sequential writing
  #   L3: window_ca — S1 full_freq → CoM → S0 windowed (cascade_com, t from L1 DSNT)
  #   L4: mamba_only — sequential writing
  #   L5: window_ca — Window CA on L0+L1 (windowed t+f, from L3 DSNT cascade)
  #   L6: mamba_only — sequential writing
  bar_token_id: 4   # <bar> token ID in the Zeng extended vocabulary
  note_gru_hidden_size: 256
  gradient_checkpointing: true  # recompute activations on backward to save memory
  decoder_layer_types: ["window_ca", "mamba_only", "window_ca", "mamba_only", "window_ca", "mamba_only"]
  decoder_layer_ca_levels:
    - [4, 5]      # L1 window_ca: S2+S3 (coarse context, bar full-attn → bar_center)
    - null        # L2 mamba_only
    - [3, 2]      # L3 window_ca: S1 first (full_freq), then S0 windowed at S1's CoM
    - null        # L4 mamba_only
    - [0, 1]      # L5 window_ca: onset+pitch (fine, t+f from L3 DSNT cascade)
    - null        # L6 mamba_only
  decoder_layer_full_freq:
    - true        # L1: full freq (S2+S3 only 8+4 freq bins, fine)
    - null        # L2 mamba_only (ignored)
    - [3]         # L3: only S1 (level 3) full_freq; S0 uses windowed at S1's CoM
    - null        # L4 mamba_only (ignored)
    - false       # L5: windowed t+f (fine-grained, L3 cascade already precise)
    - null        # L6 mamba_only (ignored)
  decoder_layer_cascade_com:
    - false       # L1: both full_freq, no cascade needed
    - null        # L2 mamba_only (ignored)
    - true        # L3: S1 CoM → S0 window center
    - null        # L4 mamba_only (ignored)
    - false       # L5: windowed, no cascade
    - null        # L6 mamba_only (ignored)

  # Window cross-attention parameters
  # Per-level window sizes (levels 0-3 used by window_ca; levels 4-5 S2/S3 by full_ca only)
  # Level: 0=Octopus(46ms)  1=Flow(93ms)  2=S0(370ms)  3=S1(741ms)
  # Coverage: L0=32×46ms=1.47s  L1=16×93ms=1.49s  L2=8×370ms=2.96s  L3=4×741ms=2.96s
  window_time_frames: [32, 16, 8, 4, 4, 4]
  window_freq_bins: [4, 4, 4, 4, 4, 4]
  window_seq_chunk_size: 10000  # large enough to avoid chunking (peak fwd mem: [B,N_q,K_l,D]~350MB, fine on 24GB)
  mamba_d_state: 128
  mamba_d_conv: 4
  mamba_expand: 2
  decoder_layers: 6
  max_seq_len: 8192
  vocab_size: 271

  label_smoothing: 0.0

  # Guided attention loss — supervises L1 Full CA to align with audio measures.
  # Weight cosine-decays from start → end, held constant during LR warmup.
  # Start high to force temporal alignment early; end low to let CE dominate.
  guidance_loss_weight: 10.0        # Enable to verify BarGRU com_t accuracy
  guidance_loss_weight_end: 0.1    # Decay to small weight
  guidance_decay_steps: 2500       # Match LR warmup

# =============================================================================
# Data
# =============================================================================
data:
  datasets:
    - musesyn
    - humsyn

  vocabulary: "zeng_extended"

  audio:
    sample_rate: 16000
    feature: "log_mel"
    n_mels: 128
    n_fft: 2048
    hop_length: 160             # 100 fps
    f_min: 27.5                 # A0
    f_max: 7040.0               # 8 octaves

  chunking:
    enabled: true
    chunk_frames: 24000         # 4 min (primary)
    overlap_frames: 12000       # 2 min overlap
    min_chunk_ratio: 0.5
    # Fallback: if a 4min chunk would exceed max_seq_len tokens, re-chunk at 2min/1min
    fallback_chunk_frames: 12000   # 2 min
    fallback_overlap_frames: 6000  # 1 min overlap

  augmentation:
    transpose:
      enabled: true
    soundfonts:
      - "TimGM6mb.sf2"
      - "FluidR3_GM.sf2"
      - "UprightPianoKW-20220221.sf2"
      - "SalamanderGrandPiano-V3+20200602.sf2"
    loudness_norm:
      target_lufs: -15

# =============================================================================
# Training
# =============================================================================
training:
  distributed:
    enabled: true
    backend: "nccl"
    num_gpus: 2

  precision: "bf16"
  batch_size: 1
  gradient_accumulation_steps: 2
  effective_batch_size: 4

  learning_rate: 2.0e-4
  weight_decay: 0.01
  max_epochs: 50
  warmup_steps: 2500
  gradient_clip: 1.0

  save_every_n_epochs: 10
  save_best: true
  save_last: true
  early_stopping_patience: 5

  wandb:
    enabled: true
    project: "clef-piano-base"
    tags: ["piano", "a2s", "serial-encoder", "rtx3090"]

# =============================================================================
# Paths
# =============================================================================
paths:
  data_dir: "data/datasets"
  output_dir: "data/experiments/clef_piano_base"
  checkpoint_dir: "checkpoints/clef_piano_base"
